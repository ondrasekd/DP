{"cells":[{"cell_type":"markdown","metadata":{"id":"Hdnfrw63GESo"},"source":["This notebook is a part of the diploma thesis \"PII detection in unstructured texts\". It is intended to be run from development environment Google Colab.\n","\n","It uses 3 main frameworks/tools:\n","- spaCy (https://spacy.io/)\n","- Presidio (https://microsoft.github.io/presidio/)\n","- Streamlit (https://streamlit.io/)\n","\n","In order to successfully run all cells, it is required to connect a personal Google disk with sufficient amount of empty space to save trained NER models weights.\n","\n","Also, in order to achieve the best results, it is recommended to run a GPU session.\n","\n","Complete source codes as well as the thesis' text itself can be found on https://github.com/ondrasekd/DP"]},{"cell_type":"markdown","metadata":{"id":"8DiH3YZwcl1I"},"source":["## Dependencies\n","Install and import spacy dependencies for either CPU or GPU utilization"]},{"cell_type":"markdown","metadata":{"id":"lawWAEdfMNTz"},"source":["### CPU\n","CPU variant can be used if you plan only to utilize CPU power while training the NER models and run CPU model variants for inference"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32103,"status":"ok","timestamp":1654876635748,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"0_CC-4T1U8OK","outputId":"70b5f720-281c-4df4-aaaf-fd56a747d4fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Collecting spacy\n","  Downloading spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","\u001b[K     |████████████████████████████████| 6.2 MB 4.1 MB/s \n","\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n","  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n","Collecting langcodes<4.0.0,>=3.2.0\n","  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 45.8 MB/s \n","\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n","  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 39.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n","Collecting srsly<3.0.0,>=2.4.3\n","  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n","\u001b[K     |████████████████████████████████| 457 kB 21.3 MB/s \n","\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n","  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Collecting spacy-legacy<3.1.0,>=3.0.9\n","  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Collecting thinc<8.1.0,>=8.0.14\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[K     |████████████████████████████████| 660 kB 36.9 MB/s \n","\u001b[?25hCollecting pathy>=0.3.5\n","  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Collecting typing-extensions<4.2.0,>=3.7.4\n","  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Collecting smart-open<6.0.0,>=5.0.0\n","  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 6.5 MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.2.0\n","    Uninstalling typing-extensions-4.2.0:\n","      Successfully uninstalled typing-extensions-4.2.0\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Attempting uninstall: smart-open\n","    Found existing installation: smart-open 6.0.0\n","    Uninstalling smart-open-6.0.0:\n","      Successfully uninstalled smart-open-6.0.0\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 smart-open-5.2.1 spacy-3.3.1 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.17 typer-0.4.1 typing-extensions-4.1.1\n"]}],"source":["!pip install --upgrade spacy\n","import spacy"]},{"cell_type":"markdown","metadata":{"id":"Mxq2Cr2tMc6n"},"source":["### GPU\n","GPU is required if you plan to train and run transformer based models"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18620,"status":"ok","timestamp":1654881762417,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"1KId4i37ZElw","outputId":"e1389953-e461-41da-8c67-f76381800e03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Collecting spacy\n","  Downloading spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","\u001b[K     |████████████████████████████████| 6.2 MB 15.3 MB/s \n","\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n","  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n","\u001b[K     |████████████████████████████████| 457 kB 70.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Collecting thinc<8.1.0,>=8.0.14\n","  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n","\u001b[K     |████████████████████████████████| 660 kB 71.8 MB/s \n","\u001b[?25hCollecting pathy>=0.3.5\n","  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n","\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n","Collecting spacy-loggers<2.0.0,>=1.0.0\n","  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n","Collecting catalogue<2.1.0,>=2.0.6\n","  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n","Collecting typer<0.5.0,>=0.3.0\n","  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Collecting typing-extensions<4.2.0,>=3.7.4\n","  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n","Collecting spacy-legacy<3.1.0,>=3.0.9\n","  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n","Collecting langcodes<4.0.0,>=3.2.0\n","  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 67.9 MB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n","Collecting smart-open<6.0.0,>=5.0.0\n","  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.2.0\n","    Uninstalling typing-extensions-4.2.0:\n","      Successfully uninstalled typing-extensions-4.2.0\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Attempting uninstall: smart-open\n","    Found existing installation: smart-open 6.0.0\n","    Uninstalling smart-open-6.0.0:\n","      Successfully uninstalled smart-open-6.0.0\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 smart-open-5.2.1 spacy-3.3.1 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.17 typer-0.4.1 typing-extensions-4.1.1\n"]}],"source":["!pip install -U spacy"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227346,"status":"ok","timestamp":1654881989759,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"JDui_p1IZSeQ","outputId":"7b4f683b-a3a2-4f9c-8ef7-95ad5e8c571f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.10.1+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.7 MB)\n","\u001b[K     |████████████▌                   | 834.1 MB 1.3 MB/s eta 0:16:29tcmalloc: large alloc 1147494400 bytes == 0x3971a000 @  0x7f2c32927615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |███████████████▉                | 1055.7 MB 1.3 MB/s eta 0:13:52tcmalloc: large alloc 1434370048 bytes == 0x7dd70000 @  0x7f2c32927615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████            | 1336.2 MB 1.3 MB/s eta 0:10:18tcmalloc: large alloc 1792966656 bytes == 0x2ba2000 @  0x7f2c32927615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████████▎      | 1691.1 MB 1.2 MB/s eta 0:06:06tcmalloc: large alloc 2241208320 bytes == 0x6d98a000 @  0x7f2c32927615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 2137.7 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2137653248 bytes == 0xf32ec000 @  0x7f2c329261e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2672066560 bytes == 0x17298c000 @  0x7f2c32927615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 2137.7 MB 399 bytes/s \n","\u001b[?25hCollecting torchvision==0.11.2+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.2%2Bcu111-cp37-cp37m-linux_x86_64.whl (24.5 MB)\n","\u001b[K     |████████████████████████████████| 24.5 MB 1.2 MB/s \n","\u001b[?25hCollecting torchaudio==0.10.1\n","  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.1%2Brocm4.1-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n","\u001b[K     |████████████████████████████████| 2.7 MB 639 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.1+cu111) (4.1.1)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2+cu111) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.2+cu111) (1.21.6)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.12.0+cu113\n","    Uninstalling torchvision-0.12.0+cu113:\n","      Successfully uninstalled torchvision-0.12.0+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.11.0+cu113\n","    Uninstalling torchaudio-0.11.0+cu113:\n","      Successfully uninstalled torchaudio-0.11.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.1+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.10.1+cu111 torchaudio-0.10.1+rocm4.1 torchvision-0.11.2+cu111\n"]}],"source":["!pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26818,"status":"ok","timestamp":1654882016565,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"DPNsZdc0Zegy","outputId":"039ac03e-cce4-4f73-e488-1b5e76f52778"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy[cuda111,transformers] in /usr/local/lib/python3.7/dist-packages (3.3.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (8.0.17)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (2.4.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (1.0.7)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (0.6.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (1.8.2)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (0.4.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (3.3.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (0.9.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (57.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (2.23.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (1.21.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (3.0.9)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (3.0.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (2.11.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (2.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (4.64.0)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (4.1.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (21.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (2.0.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (1.0.2)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (0.4.1)\n","Requirement already satisfied: cupy-cuda111<11.0.0,>=5.0.0b4 in /usr/local/lib/python3.7/dist-packages (from spacy[cuda111,transformers]) (9.4.0)\n","Collecting spacy-transformers<1.2.0,>=1.1.2\n","  Downloading spacy_transformers-1.1.6-py2.py3-none-any.whl (51 kB)\n","\u001b[K     |████████████████████████████████| 51 kB 303 kB/s \n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy[cuda111,transformers]) (3.8.0)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda111<11.0.0,>=5.0.0b4->spacy[cuda111,transformers]) (0.8)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy[cuda111,transformers]) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy[cuda111,transformers]) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda111,transformers]) (2.10)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.2->spacy[cuda111,transformers]) (1.10.1+cu111)\n","Collecting spacy-alignments<1.0.0,>=0.7.2\n","  Downloading spacy_alignments-0.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 27.1 MB/s \n","\u001b[?25hCollecting transformers<4.20.0,>=3.4.0\n","  Downloading transformers-4.19.3-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 63.0 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[cuda111,transformers]) (3.7.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.5 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.6 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 49.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[cuda111,transformers]) (4.11.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.2->spacy[cuda111,transformers]) (2019.12.20)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy[cuda111,transformers]) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy[cuda111,transformers]) (2.0.1)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 spacy-alignments-0.8.5 spacy-transformers-1.1.6 tokenizers-0.12.1 transformers-4.19.3\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: cupy-cuda111 in /usr/local/lib/python3.7/dist-packages (9.4.0)\n","Requirement already satisfied: numpy<1.24,>=1.17 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda111) (1.21.6)\n","Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.7/dist-packages (from cupy-cuda111) (0.8)\n"]}],"source":["!pip install -U spacy[cuda111,transformers]\n","!export CUDA_PATH=/usr/local/cuda-11.1\n","!export PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}\n","!export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\n","!pip install cupy-cuda111\n","\n","import spacy"]},{"cell_type":"markdown","metadata":{"id":"GVtjp_YxMWct"},"source":["## Dataset\n","\n","In this part, the following datasets are loaded and processed:\n","- **CNEC_extended** dataset, which contains only named entities supertypes (available at https://github.com/strakova/ner_tsd2016/tree/master/data/CNEC_2.0_konkol)\n","- **CNEC 2.0** dataset, which is then processed and and transformed to a special version, which contains information about lemmas (and experimentally POS tags) (original dataset available at https://github.com/strakova/ner_tsd2016/tree/master/data/CNEC_2.0)\n","\n","\n","Recognized named entities can be found in the following schematics. Coarse-grained dataset (derived from CNEC_extended) recognizes only the supertypes.\n","\n","https://ufal.mff.cuni.cz/~strakova/cnec2.0/ne-type-hierarchy.pdf"]},{"cell_type":"markdown","metadata":{"id":"5phHxLSVfbVk"},"source":["Mount google disk personal account to save/load transformed datasets and trained model weights"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16625,"status":"ok","timestamp":1654882033174,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"QK7r2bCr8dOb","outputId":"1ee11732-5cd2-467a-cb21-31286db229a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"JHP2OXl_dZhl"},"source":["Clone github repository, which contains needed datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1654418364333,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"zgziFr_rdpGn","outputId":"27701ab4-f54b-49b6-8fee-e5de6c83b292"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["%cd /content/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3742,"status":"ok","timestamp":1654342360612,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"agiO6834fKMx","outputId":"7b34b710-ff7f-4a04-b391-59862aac355a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ner_tsd2016'...\n","remote: Enumerating objects: 217, done.\u001b[K\n","remote: Total 217 (delta 0), reused 0 (delta 0), pack-reused 217\u001b[K\n","Receiving objects: 100% (217/217), 27.36 MiB | 16.31 MiB/s, done.\n","Resolving deltas: 100% (47/47), done.\n"]}],"source":["!git clone https://github.com/strakova/ner_tsd2016.git"]},{"cell_type":"markdown","metadata":{"id":"Ka7QLm6xgspJ"},"source":["Create directories structure in personal Google drive to save transformed datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329,"status":"ok","timestamp":1654343009379,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"JVj49Aq4hRwk","outputId":"ba30e8f7-13ac-4389-9b5b-88d807e789b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer’: File exists\n"]}],"source":["!mkdir '/content/drive/MyDrive/PIIAnonymizer'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets'"]},{"cell_type":"markdown","metadata":{"id":"Mk27VrYd4xzJ"},"source":["The following function serves is used to load saved spacy formatted datasets from disk and return the collection of Doc objects"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654882033174,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"8ydU5TPH4pDX"},"outputs":[],"source":["def dataset_docs_from_path(path):\n","  from spacy.tokens import DocBin\n","  nlp = spacy.blank(\"cs\")\n","\n","  # Load a collection of training docs\n","  dataset_docbin = DocBin()\n","  dataset_docbin.from_disk(path)\n","\n","  return list(dataset_docbin.get_docs(nlp.vocab))"]},{"cell_type":"markdown","metadata":{"id":"dnKIVcU9fj8c"},"source":["#### Coarse-grained CNEC2.0 Extended\n","Transform CNEC2.0 Extended dataset into the spacy binary format\n","Transformed dataset doesn't contain any additional morphological features"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":330,"status":"ok","timestamp":1654343296081,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"9fJ5EcpFiOKV","outputId":"89396398-4a3a-4ff4-e9e3-7f683cf586e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended’: File exists\n"]}],"source":["!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17036,"status":"ok","timestamp":1654343826507,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"kU_xX8ZQf0Hl","outputId":"3a1bd490-b29e-452f-a234-b9d28edc6892"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (715 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (89 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/dtest.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (89 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/etest.spacy\u001b[0m\n"]}],"source":["# convert each train, dev and test dataset to a spacy binary format\n","# group 10 sentences into each spacy doc\n","!python -m spacy convert -n 10 -c conll '/content/ner_tsd2016/data/CNEC_2.0_konkol/train.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy'\n","!python -m spacy convert -n 10 -c conll '/content/ner_tsd2016/data/CNEC_2.0_konkol/dtest.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy'\n","!python -m spacy convert -n 10 -c conll '/content/ner_tsd2016/data/CNEC_2.0_konkol/etest.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy'"]},{"cell_type":"markdown","metadata":{"id":"xHUY4Vjf5GC7"},"source":["Show examples from dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1985,"status":"ok","timestamp":1654349265667,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"IvKSbSps5MmQ","outputId":"c57d4bc7-59b5-4fb6-d193-a924dda0d40c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Jste světa znalý muž a víte stejně dobře jako já , že souvislost mezi současnými krutostmi v Jihovýchodní Asii a tou novou bankovní pobočkou hned vedle obchoďáku Zátoka je přímá a bezprostřední ; byl z toho už vzteklý jak uvázaný pes , protože zájemci o hodiny mu úplně narušili jeho denní režim a on si nemohl po obědě ani zdřímnout . I s Dubenkou , na kterou U tygra teď myslím . . . Hodil si kulovnici přes rameno a vydal se s význačným loveckým hostem do stráně , do kopce na krytou kazatelnu , aby s ním alespoň nemusel moknout . Já je normálně nosím tak \" - a ukázal hřbetem dlaně na krajinu břišní . Když zakrátko Magora zavřeli , šli Němec a Jirousová za Václavem a rozhodli se , že případ budou publikovat . Když vyhraju , což je tutovka , dostanu od každého z vás litr slivovice já . Venku se již žádně zešeřilo a tma začínala houstnout . A jak TO vysvětlíte ? Zpívali jí Krásnou Meredith , ovšem ; \n","Asii G\n","Zátoka I\n","Dubenkou P\n","U tygra I\n","Magora P\n","Němec P\n","Jirousová P\n","Václavem P\n","Krásnou Meredith O\n"]}],"source":["cnec_extended_docs = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/train.spacy')\n","\n","print(cnec_extended_docs[0])\n","\n","for ent in cnec_extended_docs[0].ents:\n","  print (ent.text, ent.label_)"]},{"cell_type":"markdown","metadata":{"id":"iNM6ToUODpM1"},"source":["### Fine-grained CNEC2.0\n","Transfer fine-grained CNEC2.0 into the spacy binary format and process dataset variations with or without additional morphological features like lemmas and POS tags"]},{"cell_type":"markdown","metadata":{"id":"EgxXA1SVqDPx"},"source":["First, CNEC2.0 must be converted from its own proprietary dataformat to some standard dataformat like conll or conllu.\n","\n","This operation is done by using a treex2conll2003 script available from Strakova's repo, which converts the Treex format to extended non-standard conll format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9RuQHIRXsAUV"},"outputs":[],"source":["# please note this script will throw some exceptions, as the morphodita tool is not installed (nor needed)\n","%cd '/content/ner_tsd2016/utils/'\n","!./make_data.sh cnec2.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BjtPkbXDwzMk"},"outputs":[],"source":["!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy'"]},{"cell_type":"markdown","metadata":{"id":"8rpfXNGYyCIl"},"source":["Then, fine-grained CNEC2.0 without additional morphological features is converted to a binary spacy format"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16036,"status":"ok","timestamp":1654347232472,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"_KamX_kVOtmE","outputId":"2535c496-7644-4ec0-8eaa-351d72c0ce06"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (720 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (90 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/dtest.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (90 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/etest.spacy\u001b[0m\n"]}],"source":["!python -m spacy convert -n 10 -c conll '/content/ner_tsd2016/data_tagged/CNEC_2.0/train.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy'\n","!python -m spacy convert -n 10 -c conll '/content/ner_tsd2016/data_tagged/CNEC_2.0/dtest.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy'\n","!python -m spacy convert -n 10 -c conll '/content/ner_tsd2016/data_tagged/CNEC_2.0/etest.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy'"]},{"cell_type":"markdown","metadata":{"id":"r7M0JPrN5tCM"},"source":["Show examples from dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2121,"status":"ok","timestamp":1654349553750,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"Sts6Ykr250jm","outputId":"611de24f-8c39-464c-d632-b5340d2a79c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Jste světa znalý muž a víte stejně dobře jako já , že souvislost mezi současnými krutostmi v Jihovýchodní Asii a tou novou bankovní pobočkou hned vedle obchoďáku Zátoka je přímá a bezprostřední ; byl z toho už vzteklý jak uvázaný pes , protože zájemci o hodiny mu úplně narušili jeho denní režim a on si nemohl po obědě ani zdřímnout . I s Dubenkou , na kterou U tygra teď myslím . . . Hodil si kulovnici přes rameno a vydal se s význačným loveckým hostem do stráně , do kopce na krytou kazatelnu , aby s ním alespoň nemusel moknout . Já je normálně nosím tak \" - a ukázal hřbetem dlaně na krajinu břišní . Když zakrátko Magora zavřeli , šli Němec a Jirousová za Václavem a rozhodli se , že případ budou publikovat . Když vyhraju , což je tutovka , dostanu od každého z vás litr slivovice já . Venku se již žádně zešeřilo a tma začínala houstnout . A jak TO vysvětlíte ? Zpívali jí Krásnou Meredith , ovšem ; \n","Asii gt\n","Zátoka if\n","Dubenkou p_\n","U tygra if\n","Magora p_\n","Němec ps\n","Jirousová ps\n","Václavem pf\n","Krásnou Meredith oa\n"]}],"source":["cnec2_docs = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/train.spacy')\n","\n","print(cnec2_docs[0])\n","\n","for ent in cnec2_docs[0].ents:\n","  print (ent.text, ent.label_)"]},{"cell_type":"markdown","metadata":{"id":"M_VwO79wy0wI"},"source":["The second transformed fine-grained dataset contains additional information about lemmas.\n","\n","It can be created by a little hack, which is to convert CNEC2.0 conll dataset to a older spacy's proprietary format, which uses the JSON annotations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3M81JUbXzvdY"},"outputs":[],"source":["!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15780,"status":"ok","timestamp":1654347872676,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"IP-B0IEvzle0","outputId":"b511447d-3431-4faf-c6b5-542eff2e3352"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/train.json\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/etest.json\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/dtest.json\u001b[0m\n"]}],"source":["!python -m spacy convert -n 10 -t json '/content/ner_tsd2016/data_tagged/CNEC_2.0/train.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json'\n","!python -m spacy convert -n 10 -t json '/content/ner_tsd2016/data_tagged/CNEC_2.0/etest.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json'\n","!python -m spacy convert -n 10 -t json '/content/ner_tsd2016/data_tagged/CNEC_2.0/dtest.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json'"]},{"cell_type":"markdown","metadata":{"id":"6311im5S1XU4"},"source":["There exists an error in spacy convert command, which allows to convert additional morphology info (lemmas) from non-standard conll formated dataset.\n","\n","There, however, exists an annotation mismatch and \"lemma\" is annotated as \"tag\". Also, CNEC2.0's lemmas annotations are morphologicaly extended (details in https://ufal.mff.cuni.cz/pdt2.0/doc/manuals/en/m-layer/html/ch02s01.html).\n","SpaCy doesn't support extended lemmas annotations, so lemmas must be converted to a standart non-extended format."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zEkMPx7CzC8E"},"outputs":[],"source":["def transform_lemmas(input_filename, output_filename):\n","  with open(input_filename) as f:\n","    lines = [line.rstrip() for line in f]\n","\n","  file_transformed = open(output_filename, 'w')\n","\n","  for line in lines:\n","    line = line.replace(\"\\\"tag\\\":\", \"\\\"lemma\\\":\")\n","    if \"\\\"lemma\\\":\" in line:\n","      line_split = line.split(\"_\")\n","      line = line_split[0]\n","      if \"-\" in line:\n","       line_split = line.split(\"-\")\n","       line = line_split[0]\n","      if not line.endswith(\",\"):\n","       line = line + \"\\\",\"\n","    file_transformed.write(line + \"\\n\")\n","\n","  file_transformed.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SiYV4fUK24zx"},"outputs":[],"source":["transform_lemmas('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/train.json', '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/train_transformed.json')\n","transform_lemmas('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/etest.json', '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/etest_transformed.json')\n","transform_lemmas('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/dtest.json', '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/dtest_transformed.json')"]},{"cell_type":"markdown","metadata":{"id":"_rbXQF4631Jd"},"source":["Then, since spacy allows to transform v2's version datasets to a v3 binary format, lemmatized dataset is converted back to a spacy binary format, only now it contains the morphological info about lemmas"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17226,"status":"ok","timestamp":1654348802835,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"HmGssSlD3Ucz","outputId":"4a09c35c-c7a5-4125-cdb4-875166ea4271"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;2m✔ Generated output file (720 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed.spacy\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (90 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/etest_transformed.spacy\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (90 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dtest_transformed.spacy\u001b[0m\n"]}],"source":["!python -m spacy convert -n 10 '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/train_transformed.json' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy'\n","!python -m spacy convert -n 10 '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/etest_transformed.json' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy'\n","!python -m spacy convert -n 10 '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/json/dtest_transformed.json' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy'"]},{"cell_type":"markdown","metadata":{"id":"DWGthOLC6KUb"},"source":["Show examples from dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1990,"status":"ok","timestamp":1654349482343,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"G4U9Aucy6NgM","outputId":"1c5e79bc-7e23-40db-b22c-bf001e5d3935"},"outputs":[{"name":"stdout","output_type":"stream","text":["Jste světa znalý muž a víte stejně dobře jako já , že souvislost mezi současnými krutostmi v Jihovýchodní Asii a tou novou bankovní pobočkou hned vedle obchoďáku Zátoka je přímá a bezprostřední ; byl z toho už vzteklý jak uvázaný pes , protože zájemci o hodiny mu úplně narušili jeho denní režim a on si nemohl po obědě ani zdřímnout . I s Dubenkou , na kterou U tygra teď myslím . . . Hodil si kulovnici přes rameno a vydal se s význačným loveckým hostem do stráně , do kopce na krytou kazatelnu , aby s ním alespoň nemusel moknout . Já je normálně nosím tak \" - a ukázal hřbetem dlaně na krajinu břišní . Když zakrátko Magora zavřeli , šli Němec a Jirousová za Václavem a rozhodli se , že případ budou publikovat . Když vyhraju , což je tutovka , dostanu od každého z vás litr slivovice já . Venku se již žádně zešeřilo a tma začínala houstnout . A jak TO vysvětlíte ? Zpívali jí Krásnou Meredith , ovšem ; \n","Asii gt Asie\n","Zátoka if zátoka\n","Dubenkou p_ Dubenka\n","U tygra if u tygr\n","Magora p_ magor\n","Němec ps Němec\n","Jirousová ps Jirousová\n","Václavem pf Václav\n","Krásnou Meredith oa krásný Meredith\n"]}],"source":["cnec2_lemmas_docs = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed.spacy')\n","\n","print(cnec2_lemmas_docs[0])\n","\n","for ent in cnec2_lemmas_docs[0].ents:\n","  print (ent.text, ent.label_, ent.lemma_)"]},{"cell_type":"markdown","metadata":{"id":"au9EqaAa61Wb"},"source":["The next step is to add morphological info \"POS tag\".\n","In order to do so, CNEC2.0 dataset in non-standard conll format must be converted to a more detailed format conllu.\n","\n","Since POS tags are again (surprise surprise) annotated in a non-standard way, POS annotations must be transformed to a standard version.\n","\n","Also, there are some important differences between conll and conllu formats, which must also be addressed before an attempt to convert dataset to spacy format from conllu.\n","\n","Function conllplus_to_conllu is designed to resolve the issues above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGe49YuI8Dau"},"outputs":[],"source":["def conllplus_to_conllu(input_filename_conll, output_filename_conllu):\n","  with open(input_filename_conll) as f:\n","    lines = f.readlines()\n","\n","  file_transformed = open(output_filename_conllu, 'w')\n","\n","  doc_id_counter = 0\n","  docs_count = 1\n","\n","  POS_mapping_single_char = {\n","      \"A\":\"ADJ\",\n","      \"C\":\"NUM\",\n","      \"D\":\"ADV\",\n","      \"I\":\"INTJ\",\n","      \"N\":\"NOUN\",\n","      \"P\":\"PRON\",\n","      \"V\":\"VERB\",\n","      \"R\":\"ADP\",\n","      \"T\":\"PART\",\n","      \"X\":\"X\",\n","      \"Z\":\"PUNCT\"\n","    }\n","  POS_mapping_double_char = {\n","      \"J,\":\"SCONJ\",\n","      \"J^\":\"CCONJ\"\n","  }\n","\n","  for line in lines:\n","    if line in ['\\n', '\\r\\n']:\n","      doc_id_counter = 0\n","      docs_count += 1\n","      file_transformed.write(line)\n","      continue\n","    word, lemma, upos, xpos, misc = line.split(\" \")\n","\n","    if \"_\" in lemma:\n","      lemma = lemma.split(\"_\")[0]\n","    if \"-\" in lemma:\n","      lemma = lemma.split(\"-\")[0]\n","\n","    if POS_mapping_single_char.get(upos[0]) is not None:\n","      upos = POS_mapping_single_char.get(upos[0])\n","    elif POS_mapping_double_char.get(upos[0:1]) is not None:\n","      upos = POS_mapping_single_char.get(upos[0:1])\n","    else:\n","      upos = \"X\"\n","\n","    doc_id_counter += 1\n","    line = str(doc_id_counter) + \"\\t\" + word + \"\\t\" + lemma + \"\\t\" + upos + \"\\t\" + \"_\" + \"\\t\" + \"_\" + \"\\t\"+ \"_\" + \"\\t\"+ \"_\" + \"\\t\"+ \"_\" + \"\\t\" + misc\n","    \n","    file_transformed.write(line)\n","\n","  print(str(docs_count) + \"documents was transformed to conllu format\")\n","  file_transformed.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":732,"status":"ok","timestamp":1654350222836,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"nuazk-yv8sc8","outputId":"c75032ab-38a7-494d-bc76-484751a1421f"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS’: File exists\n","mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy’: File exists\n"]}],"source":["!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/conllu'\n","!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":694,"status":"ok","timestamp":1654350278442,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"EpLf9wt782lW","outputId":"a11c90be-1016-478c-dcb6-047810c04910"},"outputs":[{"name":"stdout","output_type":"stream","text":["7194documents was transformed to conllu format\n","900documents was transformed to conllu format\n","901documents was transformed to conllu format\n"]}],"source":["conllplus_to_conllu('/content/ner_tsd2016/data_tagged/CNEC_2.0/train.conll', '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/conllu/train.conllu')\n","conllplus_to_conllu('/content/ner_tsd2016/data_tagged/CNEC_2.0/etest.conll', '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/conllu/etest.conllu')\n","conllplus_to_conllu('/content/ner_tsd2016/data_tagged/CNEC_2.0/dtest.conll', '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/conllu/dtest.conllu')"]},{"cell_type":"markdown","metadata":{"id":"gsG09Q69-MBN"},"source":["Conllu dataset can then be converted to spacy format"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20752,"status":"ok","timestamp":1654350434855,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"OQe4QeHd9uFa","outputId":"9429c43e-53d3-41b5-8a97-5fd7ba2752ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (720 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy/train.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (90 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy/etest.spacy\u001b[0m\n","\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (90 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy/dtest.spacy\u001b[0m\n"]}],"source":["!python -m spacy convert -n 10 '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/conllu/train.conllu' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy'\n","!python -m spacy convert -n 10 '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/conllu/etest.conllu' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy'\n","!python -m spacy convert -n 10 '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/conllu/dtest.conllu' '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy'"]},{"cell_type":"markdown","metadata":{"id":"NhlVhkw4-RmC"},"source":["Show examples from dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3241,"status":"ok","timestamp":1654381474723,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"E1IJL4_O-WEf","outputId":"3378f393-9b6c-4321-a8ae-02f048a0ed74"},"outputs":[{"name":"stdout","output_type":"stream","text":["Jste světa znalý muž a víte stejně dobře jako já , že souvislost mezi současnými krutostmi v Jihovýchodní Asii a tou novou bankovní pobočkou hned vedle obchoďáku Zátoka je přímá a bezprostřední ; byl z toho už vzteklý jak uvázaný pes , protože zájemci o hodiny mu úplně narušili jeho denní režim a on si nemohl po obědě ani zdřímnout . I s Dubenkou , na kterou U tygra teď myslím . . . Hodil si kulovnici přes rameno a vydal se s význačným loveckým hostem do stráně , do kopce na krytou kazatelnu , aby s ním alespoň nemusel moknout . Já je normálně nosím tak \" - a ukázal hřbetem dlaně na krajinu břišní . Když zakrátko Magora zavřeli , šli Němec a Jirousová za Václavem a rozhodli se , že případ budou publikovat . Když vyhraju , což je tutovka , dostanu od každého z vás litr slivovice já . Venku se již žádně zešeřilo a tma začínala houstnout . A jak TO vysvětlíte ? Zpívali jí Krásnou Meredith , ovšem ; \n"]}],"source":["cnec2_lemmas_pos_docs = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas_POS/spacy/train.spacy')\n","\n","print(cnec2_lemmas_pos_docs[0])\n","\n","for ent in cnec2_lemmas_pos_docs[0].ents:\n","  print (ent.text, ent.label_, ent.lemma_, ent.pos)"]},{"cell_type":"markdown","metadata":{"id":"hYAjFK2M-p1A"},"source":["Unfortunately, there is an error in spacy convert tool, which prevents to convert named entities annotations correctly from conllu format.\n","\n","Specifically, there is a problem with predefined regex MISC_NER_PATTERN, which is designed incorrectly and doesn't allow to process named entities annotations.\n","\n","You can see it for yourself at\n","https://github.com/explosion/spaCy/blob/master/spacy/training/converters/conllu_to_docs.py\n"]},{"cell_type":"markdown","metadata":{"id":"yhQI-dgpdkQn"},"source":["### Data exploration\n","In this part, data from transformed dataset are explored and cleaned"]},{"cell_type":"markdown","metadata":{"id":"GsZKgMnjBlqc"},"source":["The following function prints all named antity categories available in the provided dataset and counts total NEs count in the same category and also the NE's occurence in a context of the whole dataset "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAVTxrjXsigW"},"outputs":[],"source":["def print_NE_occurences_docs(dataset_docs):\n","  from spacy.tokens import DocBin\n","  NEs = {}\n","\n","  predefinedNEs = [\"ah\", \"at\", \"az\", \"gc\", \"gh\", \"gl\", \"gq\", \"gr\",\n","                   \"gs\", \"gt\", \"gu\", \"g_\", \"ia\", \"ic\", \"if\", \"io\",\n","                   \"i_\", \"me\", \"mi\", \"mn\", \"ms\", \"na\", \"nb\", \"nc\",\n","                   \"ni\", \"no\", \"ns\", \"n_\", \"oa\", \"oe\", \"om\", \"op\",\n","                   \"or\", \"o_\", \"pc\", \"pd\", \"pf\", \"pm\", \"pp\", \"ps\",\n","                   \"p_\", \"td\", \"tf\", \"th\", \"tm\", \"ty\"]\n","\n","  for doc in dataset_docs:\n","    for ent in doc.ents:\n","      if NEs.get(ent.label_) is not None:\n","        NEs[ent.label_] += 1\n","      else:\n","        NEs[ent.label_] = 1\n","\n","  total_NEs_count = sum(NEs.values()) \n","  print(\"total detected named entity categories: \" + str(len(NEs)))\n","  print(\"total named entites count: \" + str(total_NEs_count))\n","\n","  for predefinedNE in predefinedNEs:\n","    if (predefinedNE not in NEs.keys()):\n","      print(\"dataset is missing entity \" + predefinedNE)\n","\n","  NEs_sorted = dict(sorted(NEs.items(), key=lambda item: item[1]))\n","\n","  print(\"NE\\tcount\\tpercent\")\n","  for NE, NE_count in NEs_sorted.items():\n","    NE_percent = (NE_count/total_NEs_count) * 100\n","    NE_percent_short = \"{:.2f}\".format(NE_percent)\n","    print(str(NE) + \"\\t\" + str(NE_count) + \"\\t\" + str(NE_percent_short))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p8xdGjiDdyU2"},"outputs":[],"source":["def print_NE_occurrences_path(dataset_path):\n","  dataset_docs = dataset_docs_from_path(dataset_path)\n","  print_NE_occurences_docs(dataset_docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZhgjDJ2tJiN"},"outputs":[],"source":["docs_merged = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed.spacy') + dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dtest_transformed.spacy') + dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/etest_transformed.spacy')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1654351737467,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"PV0SCAnwuJoR","outputId":"beb2ddb3-f599-43ec-a8c5-0bffe387f775"},"outputs":[{"name":"stdout","output_type":"stream","text":["total detected named entity categories: 46\n","total named entites count: 26555\n","NE\tcount\tpercent\n","mi\t22\t0.08\n","tf\t24\t0.09\n","i_\t40\t0.15\n","gh\t54\t0.20\n","ms\t73\t0.27\n","pm\t79\t0.30\n","gt\t81\t0.31\n","pd\t98\t0.37\n","g_\t102\t0.38\n","pp\t103\t0.39\n","me\t104\t0.39\n","gl\t106\t0.40\n","na\t106\t0.40\n","az\t121\t0.46\n","ns\t137\t0.52\n","or\t141\t0.53\n","gq\t153\t0.58\n","o_\t165\t0.62\n","ni\t175\t0.66\n","ah\t184\t0.69\n","gr\t204\t0.77\n","om\t209\t0.79\n","at\t229\t0.86\n","ia\t238\t0.90\n","mn\t240\t0.90\n","pc\t251\t0.95\n","nb\t273\t1.03\n","gs\t301\t1.13\n","no\t316\t1.19\n","p_\t317\t1.19\n","op\t404\t1.52\n","oe\t475\t1.79\n","td\t515\t1.94\n","tm\t577\t2.17\n","n_\t596\t2.24\n","io\t776\t2.92\n","if\t846\t3.19\n","gc\t1083\t4.08\n","ty\t1295\t4.88\n","th\t1436\t5.41\n","ic\t1474\t5.55\n","oa\t1776\t6.69\n","gu\t1878\t7.07\n","nc\t2021\t7.61\n","pf\t2901\t10.92\n","ps\t3856\t14.52\n"]}],"source":["print_NE_occurences_docs(docs_merged)"]},{"cell_type":"markdown","metadata":{"id":"HtWWrP6U3BIS"},"source":["#### Data cleaning"]},{"cell_type":"markdown","metadata":{"id":"_0IvMQfGDS_1"},"source":["Dataset NEs' occurrences were analyzed (further info in the main diploma thesis' text).\n","\n","Some NEs will be removed from the dataset by function remove_redundant_NEs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QRQRerrKJUT0"},"outputs":[],"source":["def remove_redundant_NEs(docs):\n","  NEs_to_remove = {\n","      \"pp\",\n","      \"mi\"\n","  }\n","\n","  for doc in docs:\n","    doc_ents = [ent for ent in doc.ents if ent.label_ not in NEs_to_remove]\n","    doc.set_ents(doc_ents)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FTDU-G5z4YX8"},"outputs":[],"source":["remove_redundant_NEs(docs_merged)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1654351928577,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"oaFhxCPDXOWb","outputId":"e622d832-358a-4cb3-d785-e37cae8c51da"},"outputs":[{"name":"stdout","output_type":"stream","text":["total detected named entity categories: 44\n","total named entites count: 26430\n","dataset is missing entity mi\n","dataset is missing entity pp\n","NE\tcount\tpercent\n","tf\t24\t0.09\n","i_\t40\t0.15\n","gh\t54\t0.20\n","ms\t73\t0.28\n","pm\t79\t0.30\n","gt\t81\t0.31\n","pd\t98\t0.37\n","g_\t102\t0.39\n","me\t104\t0.39\n","gl\t106\t0.40\n","na\t106\t0.40\n","az\t121\t0.46\n","ns\t137\t0.52\n","or\t141\t0.53\n","gq\t153\t0.58\n","o_\t165\t0.62\n","ni\t175\t0.66\n","ah\t184\t0.70\n","gr\t204\t0.77\n","om\t209\t0.79\n","at\t229\t0.87\n","ia\t238\t0.90\n","mn\t240\t0.91\n","pc\t251\t0.95\n","nb\t273\t1.03\n","gs\t301\t1.14\n","no\t316\t1.20\n","p_\t317\t1.20\n","op\t404\t1.53\n","oe\t475\t1.80\n","td\t515\t1.95\n","tm\t577\t2.18\n","n_\t596\t2.26\n","io\t776\t2.94\n","if\t846\t3.20\n","gc\t1083\t4.10\n","ty\t1295\t4.90\n","th\t1436\t5.43\n","ic\t1474\t5.58\n","oa\t1776\t6.72\n","gu\t1878\t7.11\n","nc\t2021\t7.65\n","pf\t2901\t10.98\n","ps\t3856\t14.59\n"]}],"source":["print_NE_occurences_docs(docs_merged)"]},{"cell_type":"markdown","metadata":{"id":"7T6_zi0SD35y"},"source":["The same thing is then done for each dataset (train, dev, test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oOK2jpTS_x_B"},"outputs":[],"source":["train_transformed = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed.spacy')\n","dev_transformed = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dtest_transformed.spacy')\n","test_transformed = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/etest_transformed.spacy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-VSl8hYBfBM"},"outputs":[],"source":["remove_redundant_NEs(train_transformed)\n","remove_redundant_NEs(dev_transformed)\n","remove_redundant_NEs(test_transformed)"]},{"cell_type":"markdown","metadata":{"id":"oj2JyClTEaar"},"source":["The following function is used to serialize spacy's Doc objects and transform it to a DocBin.\n","\n","DocBin can then be saved to a disk."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zpbcz6K-F-6W"},"outputs":[],"source":["def serialize_docs(docs):\n","  from spacy.tokens import DocBin\n","  doc_bin = DocBin()\n","  for doc in docs:\n","    doc_bin.add(doc)\n","\n","  return doc_bin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQnYb-pmGl_9"},"outputs":[],"source":["train_transformed_doc_bin = serialize_docs(train_transformed)\n","train_transformed_doc_bin.to_disk('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy')\n","\n","dev_transformed_doc_bin = serialize_docs(dev_transformed)\n","dev_transformed_doc_bin.to_disk('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy')\n","\n","test_transformed_doc_bin = serialize_docs(test_transformed)\n","test_transformed_doc_bin.to_disk('/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')"]},{"cell_type":"markdown","metadata":{"id":"PsUYridHkiPI"},"source":["# NER model training\n","This part will be dedicated to training a NER model with use of a spaCy framework.\n","\n","First, less computational power demanding CPU models shall be trained on different versions of created datasets. Models shall than be evaluated (F1 score was selected as the main evaluation criterion).\n"]},{"cell_type":"markdown","metadata":{"id":"McBuqcUZOIjZ"},"source":["SpaCy uses (in version v3) as a means to specify model architecture config.cfg files. These files were prepared separatelly of this notebook and can be obtained in a project github repository."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jN5vaExqRXPB"},"outputs":[],"source":["!mkdir '/content/drive/MyDrive/PIIAnonymizer/models'"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5501,"status":"ok","timestamp":1654882326011,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"wYX2yW7nOe04","outputId":"85c3e1ff-b0b0-4336-f8aa-65d4ab0e65b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Cloning into 'DP'...\n","remote: Enumerating objects: 265, done.\u001b[K\n","remote: Counting objects: 100% (154/154), done.\u001b[K\n","remote: Compressing objects: 100% (104/104), done.\u001b[K\n","remote: Total 265 (delta 83), reused 120 (delta 49), pack-reused 111\u001b[K\n","Receiving objects: 100% (265/265), 46.50 MiB | 11.40 MiB/s, done.\n","Resolving deltas: 100% (129/129), done.\n"]}],"source":["%cd '/content'\n","!git clone 'https://github.com/ondrasekd/DP.git'"]},{"cell_type":"markdown","metadata":{"id":"lcD2WangWOen"},"source":["Function display_model_inference_example serves to show a minimal example of classified NEs detected by a provided model"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":286,"status":"ok","timestamp":1654790337059,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"MtHZ0SUpVtOf"},"outputs":[],"source":["def display_model_inference_example(path_to_spacy_model):\n","  from spacy import displacy\n","  nlp = spacy.load(path_to_spacy_model)\n","  doc = nlp(\"Pan Karel se nechal zaměstnat v Google, protože Microsoft se mu nezdál. Povídal, že v Čechách se tohle nenosí.\")\n","  displacy.render(doc,jupyter=True, style = \"ent\")"]},{"cell_type":"markdown","metadata":{"id":"0bGBJfBSaNLC"},"source":["This function sets the temporary global train variables to clean up the code a little"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1654790338250,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"Gx0f0U6UZeG0"},"outputs":[],"source":["def set_temp_train_variables(config_path, model_dir_path, test_dataset_path):\n","  global cfg\n","  cfg = config_path\n","\n","  global model_dir\n","  model_dir = model_dir_path\n","\n","  global model_eval_path \n","  model_eval_path = model_dir_path + \"/model-best_eval/\"\n","\n","  global model_eval_path_json\n","  model_eval_path_json = model_eval_path + \"eval.json\"\n","\n","  global model_best_path\n","  model_best_path = model_dir_path + \"/model-best\"\n","\n","  global test_dataset\n","  test_dataset = test_dataset_path"]},{"cell_type":"markdown","metadata":{"id":"J6FYaTciE4DC"},"source":["### CPU models"]},{"cell_type":"markdown","metadata":{"id":"mRMKScHJW7vw"},"source":["**Coarse-grained CPU model**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":494525,"status":"ok","timestamp":1654359860279,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"rn4l81LsUAxl","outputId":"f0b835cf-38e1-4bfe-91eb-b8baa9faecda"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse’: File exists\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-04 16:16:10,025] [INFO] Set up nlp object from config\n","[2022-06-04 16:16:10,033] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/dtest.spacy\n","[2022-06-04 16:16:10,034] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/train.spacy\n","[2022-06-04 16:16:10,034] [INFO] Pipeline: ['tok2vec', 'ner']\n","[2022-06-04 16:16:10,039] [INFO] Created vocabulary\n","[2022-06-04 16:16:10,040] [INFO] Finished initializing nlp object\n","[2022-06-04 16:16:13,399] [DEBUG] [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed and load the table in your config. The languages with lexeme normalization tables are currently: cs, da, de, el, en, id, lb, mk, pt, ru, sr, ta, th\n","\n","Load the table in your config with:\n","\n","[initialize.lookups]\n","@misc = \"spacy.LookupsDataLoader.v1\"\n","lang = ${nlp.lang}\n","tables = [\"lexeme_norm\"]\n","\n","[2022-06-04 16:16:14,314] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-04 16:16:14,326] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/dtest.spacy\n","[2022-06-04 16:16:14,326] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/train.spacy\n","[2022-06-04 16:16:14,351] [DEBUG] Removed existing output directory: /content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse/model-best\n","[2022-06-04 16:16:14,372] [DEBUG] Removed existing output directory: /content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse/model-last\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  --------  ------  ------  ------  ------\n","  0       0          0.00    151.93    0.75    0.82    0.69    0.01\n","  0     200       6308.50   8260.36   31.89   45.94   24.42    0.32\n","  0     400        945.74   4729.62   45.13   50.12   41.04    0.45\n","  0     600       4943.51   4281.29   50.53   53.85   47.59    0.51\n","  1     800        452.93   3829.11   55.97   59.22   53.05    0.56\n","  1    1000        583.81   3528.98   58.44   60.73   56.33    0.58\n","  1    1200        600.49   3206.58   59.21   59.06   59.35    0.59\n","  1    1400       1773.03   3210.86   62.24   63.86   60.69    0.62\n","  2    1600       1364.22   2589.78   58.00   59.77   56.33    0.58\n","  2    1800        768.38   2711.41   63.65   64.91   62.43    0.64\n","  2    2000        857.31   2796.78   66.25   67.32   65.21    0.66\n","  3    2200       2106.95   2443.32   63.32   63.67   62.98    0.63\n","  3    2400        775.52   2186.44   64.75   65.81   63.72    0.65\n","  3    2600        806.94   2142.46   63.85   65.60   62.18    0.64\n","  3    2800        687.84   2041.39   65.56   67.83   63.42    0.66\n","  4    3000        725.76   1726.14   65.02   66.25   63.82    0.65\n","  4    3200        860.86   1754.91   64.94   65.78   64.12    0.65\n","  4    3400        836.90   1806.18   66.17   67.92   64.52    0.66\n","  5    3600        854.65   1765.52   66.20   66.35   66.05    0.66\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse/model-last\n","mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse/model-best_eval/’: File exists\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     -    \n","NER P   64.43\n","NER R   62.21\n","NER F   63.30\n","SPEED   5362 \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","        P       R       F\n","G   63.91   61.38   62.62\n","P   59.39   73.12   65.55\n","O   67.35   43.19   52.63\n","I   40.69   43.83   42.20\n","T   91.88   86.14   88.92\n","M   84.00   43.75   57.53\n","A   80.85   69.09   74.51\n","\n","\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse/model-best_eval\n","\u001b[38;5;2m✔ Saved results to\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse/model-best_eval/eval.json\u001b[0m\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/CPU_coarse.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/CPU_coarse',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0_extended/spacy/etest.spacy')\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"iP0xbq5uXD5t"},"source":["**Fine-grained CPU model without lemmas**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":857448,"status":"ok","timestamp":1654360717719,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"UcbEdgEoXM3k","outputId":"0f780e70-3fc7-4160-d0d6-ca489ccd18b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-04 16:24:24,970] [INFO] Set up nlp object from config\n","[2022-06-04 16:24:24,979] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/dtest.spacy\n","[2022-06-04 16:24:24,980] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/train.spacy\n","[2022-06-04 16:24:24,980] [INFO] Pipeline: ['tok2vec', 'ner']\n","[2022-06-04 16:24:24,984] [INFO] Created vocabulary\n","[2022-06-04 16:24:24,985] [INFO] Finished initializing nlp object\n","[2022-06-04 16:24:28,657] [DEBUG] [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed and load the table in your config. The languages with lexeme normalization tables are currently: cs, da, de, el, en, id, lb, mk, pt, ru, sr, ta, th\n","\n","Load the table in your config with:\n","\n","[initialize.lookups]\n","@misc = \"spacy.LookupsDataLoader.v1\"\n","lang = ${nlp.lang}\n","tables = [\"lexeme_norm\"]\n","\n","[2022-06-04 16:24:29,646] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-04 16:24:29,656] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/dtest.spacy\n","[2022-06-04 16:24:29,657] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/train.spacy\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  --------  ------  ------  ------  ------\n","  0       0          0.00     89.19    0.00    0.00    0.00    0.00\n","  0     200       1850.59   9381.27   39.94   41.68   38.34    0.40\n","  0     400       1507.02   6209.75   48.19   49.18   47.25    0.48\n","  0     600       4523.76   5766.14   51.92   59.53   46.03    0.52\n","  1     800       1948.04   5564.50   53.80   56.98   50.97    0.54\n","  1    1000       5240.74   4831.86   59.78   63.72   56.29    0.60\n","  1    1200       1705.63   4472.45   59.56   63.31   56.22    0.60\n","  1    1400       1180.72   4627.00   60.88   65.85   56.62    0.61\n","  2    1600       1059.83   3938.76   59.25   61.21   57.40    0.59\n","  2    1800       3404.32   4092.03   61.61   61.24   61.98    0.62\n","  2    2000       1921.12   3943.98   62.80   66.00   59.91    0.63\n","  3    2200       1267.47   3690.80   64.06   67.08   61.30    0.64\n","  3    2400       2098.76   3427.98   63.70   63.63   63.77    0.64\n","  3    2600       1773.21   3351.25   64.23   68.33   60.59    0.64\n","  3    2800       5000.15   3369.97   64.37   64.26   64.48    0.64\n","  4    3000       1388.50   3091.06   64.57   63.81   65.34    0.65\n","  4    3200       2607.29   3055.32   62.71   64.00   61.48    0.63\n","  4    3400       1988.66   3263.09   65.86   67.76   64.06    0.66\n","  5    3600       1636.35   3156.05   65.89   68.40   63.56    0.66\n","  5    3800       1484.85   2460.13   64.30   66.63   62.12    0.64\n","  5    4000       2534.22   2767.25   63.25   62.56   63.95    0.63\n","  5    4200       2886.24   2857.93   64.27   64.37   64.16    0.64\n","  6    4400       1829.91   2701.89   66.07   66.29   65.84    0.66\n","  6    4600       1757.74   2310.74   65.16   65.44   64.88    0.65\n","  6    4800       2006.74   2445.67   65.16   65.01   65.31    0.65\n","  6    5000       2506.26   2660.72   65.88   66.84   64.95    0.66\n","  7    5200       2106.97   2005.78   64.45   64.64   64.27    0.64\n","  7    5400       2439.56   2269.26   65.08   65.47   64.70    0.65\n","  7    5600       6609.31   2161.02   64.67   65.74   63.63    0.65\n","  8    5800       1952.37   2253.75   64.90   64.12   65.70    0.65\n","  8    6000       1807.19   1999.51   64.15   65.17   63.16    0.64\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/model-last\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     -    \n","NER P   64.42\n","NER R   63.56\n","NER F   63.99\n","SPEED   9249 \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","          P        R        F\n","tf    16.67    50.00    25.00\n","ps    67.12    73.22    70.04\n","nc    69.50    92.02    79.19\n","pp    33.33    20.00    25.00\n","ni    25.58    68.75    37.29\n","pf    74.48    76.99    75.72\n","gu    55.05    67.70    60.72\n","if    11.86    20.90    15.14\n","ah    65.00    65.00    65.00\n","gc    70.71    59.83    64.81\n","pm    16.67    25.00    20.00\n","oa    66.86    47.28    55.39\n","p_    10.61    19.44    13.73\n","mn    41.18    25.93    31.82\n","ty    93.89    91.11    92.48\n","op    20.00    12.82    15.62\n","ia    31.25    16.13    21.28\n","io    60.66    56.92    58.73\n","g_    33.33    16.67    22.22\n","ic    40.98    31.25    35.46\n","nb    62.50    34.48    44.44\n","th    96.74    96.22    96.48\n","oe    81.82    56.25    66.67\n","gr    71.43    23.81    35.71\n","pc    60.00    34.62    43.90\n","gs    66.67    50.00    57.14\n","az    58.33    70.00    63.64\n","at    74.07    80.00    76.92\n","n_    26.47    12.16    16.67\n","gt    50.00   100.00    66.67\n","pd    72.73    88.89    80.00\n","td    92.16    81.03    86.24\n","tm    86.57    98.31    92.06\n","ns    50.00   100.00    66.67\n","gh    25.00    20.00    22.22\n","gq    50.00    16.67    25.00\n","no    51.28    60.61    55.56\n","om    96.43    93.10    94.74\n","me   100.00    93.75    96.77\n","gl    66.67    20.00    30.77\n","ms   100.00    40.00    57.14\n","o_    28.57    10.53    15.38\n","or     0.00     0.00     0.00\n","na   100.00    25.00    40.00\n","i_     0.00     0.00     0.00\n","mi   100.00   100.00   100.00\n","\n","\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/model-best_eval\n","\u001b[38;5;2m✔ Saved results to\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/model-best_eval/eval.json\u001b[0m\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/CPU_fine_nomorph.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/no_morph/spacy/etest.spacy')\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"EytdIyQXebxf"},"source":["**Fine-grained CPU model with lemmas**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10925878,"status":"ok","timestamp":1654375748274,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"fwQ4IfwOefbU","outputId":"a944bc60-e2f4-4ab0-ae32-439d7d41e8e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy-lookups-data\n","  Downloading spacy_lookups_data-1.0.3-py2.py3-none-any.whl (98.5 MB)\n","\u001b[K     |████████████████████████████████| 98.5 MB 116 kB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy-lookups-data) (57.4.0)\n","Installing collected packages: spacy-lookups-data\n","Successfully installed spacy-lookups-data-1.0.3\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_lemmas\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-04 16:38:52,836] [INFO] Set up nlp object from config\n","[2022-06-04 16:38:52,845] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dtest_transformed.spacy\n","[2022-06-04 16:38:52,846] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed.spacy\n","[2022-06-04 16:38:52,846] [INFO] Pipeline: ['tok2vec', 'trainable_lemmatizer', 'ner']\n","[2022-06-04 16:38:52,852] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm', 'lemma_lookup']\n","[2022-06-04 16:38:53,092] [INFO] Added vocab lookups: lexeme_norm, lemma_lookup\n","[2022-06-04 16:38:53,093] [INFO] Created vocabulary\n","[2022-06-04 16:38:53,093] [INFO] Finished initializing nlp object\n","[2022-06-04 16:39:18,088] [INFO] Initialized pipeline components: ['tok2vec', 'trainable_lemmatizer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-04 16:39:18,099] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dtest_transformed.spacy\n","[2022-06-04 16:39:18,100] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed.spacy\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'trainable_lemmatizer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS TRAIN...  LOSS NER  LEMMA_ACC  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  -------------  --------  ---------  ------  ------  ------  ------\n","  0       0          0.00         156.88     92.66      54.82    0.00    0.00    0.00    0.27\n","  0     200        814.27       19755.54   8803.14      79.22   41.89   42.91   40.92    0.61\n","  0     400       1260.85       11473.14   6059.24      85.38   51.77   53.30   50.32    0.69\n","  0     600       1307.13        8947.14   6389.78      87.74   48.52   55.04   43.38    0.68\n","  1     800       1142.48        6637.45   5859.50      88.95   55.98   60.86   51.82    0.72\n","  1    1000       1083.27        5281.70   4615.24      89.29   58.07   60.36   55.94    0.74\n","  1    1200       1165.15        5045.12   4213.65      90.03   58.55   60.43   56.80    0.74\n","  1    1400       1319.25        5128.87   4555.37      90.45   60.94   64.71   57.58    0.76\n","  2    1600        879.88        3098.51   3801.30      90.89   61.67   65.24   58.48    0.76\n","  2    1800        987.97        3099.62   3915.94      90.76   63.87   64.20   63.56    0.77\n","  2    2000       1028.41        2988.80   3806.79      90.97   61.86   64.57   59.37    0.76\n","  3    2200       1033.38        2862.68   3825.46      90.73   65.20   65.92   64.48    0.78\n","  3    2400        723.85        1755.49   3468.88      91.04   64.35   64.79   63.91    0.78\n","  3    2600        848.04        1892.80   3152.84      91.13   64.46   66.25   62.77    0.78\n","  3    2800       1011.22        2203.44   3119.98      91.31   65.13   64.70   65.56    0.78\n","  4    3000        774.29        1587.53   2736.49      91.34   65.85   65.23   66.49    0.79\n","  4    3200        676.88        1294.98   2670.04      91.38   64.23   66.65   61.98    0.78\n","  4    3400        922.71        1695.05   2942.47      91.31   65.63   66.94   64.38    0.78\n","  5    3600        917.29        1607.00   3005.29      91.07   64.99   67.14   62.98    0.78\n","  5    3800        594.82        1004.45   2287.19      91.22   62.87   67.54   58.80    0.77\n","  5    4000        768.66        1189.90   2445.70      91.49   63.83   63.82   63.84    0.78\n","  5    4200        858.39        1296.13   2540.18      91.43   65.35   65.64   65.06    0.78\n","  6    4400        744.40        1091.20   2272.58      91.59   65.69   65.37   66.02    0.79\n","  6    4600        632.42         873.82   2064.04      91.80   61.79   65.36   58.58    0.77\n","  6    4800        765.57        1022.70   2083.00      91.30   66.06   66.76   65.38    0.79\n","  6    5000        843.45        1075.17   2230.89      91.50   65.89   66.15   65.63    0.79\n","  7    5200        648.17         789.54   1605.49      91.35   64.42   64.54   64.31    0.78\n","  7    5400        732.99         861.46   1854.30      91.46   64.97   65.47   64.48    0.78\n","  7    5600        829.32         937.32   1938.24      91.45   64.68   64.10   65.27    0.78\n","  8    5800        866.18         961.65   1935.54      91.65   66.01   66.07   65.95    0.79\n","  8    6000        591.65         633.56   1768.45      91.61   65.55   66.54   64.59    0.79\n","  8    6200        693.20         705.94   1353.22      91.59   64.76   64.85   64.66    0.78\n","  8    6400        824.86         828.80   1654.80      91.61   65.53   65.79   65.27    0.79\n","  9    6600        690.60         689.38   1494.03      91.48   65.09   65.23   64.95    0.78\n","  9    6800        711.43         675.20   1426.21      91.60   65.36   65.84   64.88    0.78\n","  9    7000        811.75         751.38   1492.99      91.74   66.50   66.73   66.27    0.79\n"," 10    7200        856.83         795.39   1462.28      91.61   66.27   68.21   64.45    0.79\n"," 10    7400        613.32         545.25   1204.90      91.74   65.67   65.42   65.92    0.79\n"," 10    7600        688.86         594.55   1277.69      91.43   66.70   66.88   66.52    0.79\n"," 10    7800        806.31         677.04   1283.41      91.44   66.70   66.21   67.20    0.79\n"," 11    8000        742.75         616.57   1218.69      91.68   67.21   69.22   65.31    0.79\n"," 11    8200        697.97         563.61   1148.26      91.61   66.67   67.21   66.13    0.79\n"," 11    8400        756.55         589.77   1260.49      91.53   66.52   66.63   66.42    0.79\n"," 11    8600        852.26         652.82   1170.03      91.53   66.19   66.79   65.59    0.79\n"," 12    8800        649.49         484.93   1061.76      91.73   66.11   68.15   64.20    0.79\n"," 12    9000        682.36         505.50   1099.31      91.73   67.06   67.84   66.31    0.79\n"," 12    9200        770.39         538.07   1060.44      91.90   65.16   65.23   65.09    0.79\n"," 13    9400        802.76         563.29   1049.15      91.69   66.30   67.29   65.34    0.79\n"," 13    9600        571.64         386.05    833.93      92.05   65.74   65.43   66.06    0.79\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_lemmas/model-last\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     100.00\n","LEMMA   91.49 \n","NER P   65.70 \n","NER R   61.40 \n","NER F   63.48 \n","SPEED   557   \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","          P        R        F\n","gu    48.46    68.32    56.70\n","ps    71.18    69.78    70.47\n","nc    72.64    68.54    70.53\n","pf    77.52    73.01    75.20\n","gr    36.00    42.86    39.13\n","oa    51.08    49.37    50.21\n","gs    43.75    43.75    43.75\n","ty    91.60    88.89    90.23\n","gc    67.23    68.38    67.80\n","p_     9.09     8.33     8.70\n","pm    22.22    25.00    23.53\n","mn    42.11    29.63    34.78\n","if    25.00    25.37    25.19\n","op    39.13    23.08    29.03\n","io    56.36    47.69    51.67\n","g_    71.43    41.67    52.63\n","ic    42.11    30.00    35.04\n","th    96.24    96.76    96.50\n","gq    16.67    11.11    13.33\n","oe    85.29    60.42    70.73\n","ia    36.36    12.90    19.05\n","pc    50.00    30.77    38.10\n","ah    75.00    60.00    66.67\n","az   100.00    80.00    88.89\n","at    66.67    72.00    69.23\n","n_    44.12    20.27    27.78\n","pd    88.89    88.89    88.89\n","pp    13.33    40.00    20.00\n","td    95.92    81.03    87.85\n","tm    89.06    96.61    92.68\n","gh    27.27    60.00    37.50\n","ns    60.00    90.00    72.00\n","or     0.00     0.00     0.00\n","om    96.43    93.10    94.74\n","me   100.00    93.75    96.77\n","gt    50.00    75.00    60.00\n","gl    27.27    30.00    28.57\n","no    69.57    48.48    57.14\n","o_    33.33    15.79    21.43\n","ms    50.00    20.00    28.57\n","ni    66.67    50.00    57.14\n","nb    70.00    48.28    57.14\n","na    50.00    25.00    33.33\n","tf   100.00    50.00    66.67\n","i_     0.00     0.00     0.00\n","mi   100.00   100.00   100.00\n","\n","\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_lemmas/model-best_eval\n","\u001b[38;5;2m✔ Saved results to\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_lemmas/model-best_eval/eval.json\u001b[0m\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/CPU_fine_lemmas.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_lemmas',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/etest_transformed_clean.spacy')\n","\n","# in this case, since model uses lemmas, spacy-lookups-data should be installed\n","!pip install spacy-lookups-data\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"Dqp2UF_Rh-20"},"source":["### GPU models\n","NOTE: to train the following models, GPU session must be enabled (go to Runtime-> Change runtime type-> choose GPU)\n","\n","Since the developed anonymization tool needs to use a fine-grained dataset, transformed and cleaned dataset CNEC2.0 shall be used in every GPU training."]},{"cell_type":"markdown","metadata":{"id":"SV16PU0UJ8He"},"source":["**GPU bert-base-multilingual-uncased**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65bzkQWDiRKX","outputId":"c91e8431-8ba5-4755-8102-2fe261170d1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy-lookups-data in /usr/local/lib/python3.7/dist-packages (1.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy-lookups-data) (57.4.0)\n","mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_uncased’: File exists\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_uncased\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-04 22:43:42,947] [INFO] Set up nlp object from config\n","[2022-06-04 22:43:42,956] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-04 22:43:42,958] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","[2022-06-04 22:43:42,958] [INFO] Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\n","[2022-06-04 22:43:42,963] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm', 'lemma_lookup']\n","[2022-06-04 22:43:43,179] [INFO] Added vocab lookups: lexeme_norm, lemma_lookup\n","[2022-06-04 22:43:43,179] [INFO] Created vocabulary\n","[2022-06-04 22:43:43,180] [INFO] Finished initializing nlp object\n","Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-06-04 22:43:54,199] [INFO] Initialized pipeline components: ['transformer', 'trainable_lemmatizer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-04 22:43:54,209] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-04 22:43:54,210] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS TRAIN...  LOSS NER  LEMMA_ACC  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  -------------  --------  ---------  ------  ------  ------  ------\n","tcmalloc: large alloc 1339023360 bytes == 0x15f252000 @  0x7f292e1542a4 0x7f2922eeef93 0x7f2922ef0a5d 0x7f2922eed235 0x7f2922eed9de 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x548ae9 0x51566f 0x593dd7 0x511e2c 0x549576 0x593fce 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x548ae9 0x51566f\n","tcmalloc: large alloc 1345896448 bytes == 0x113bf0000 @  0x7f292e1542a4 0x7f2922eeef93 0x7f2922eef120 0x7f2922eef120 0x7f2922ef0a5d 0x7f2922eed235 0x7f2922eed9de 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x548ae9 0x51566f 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x548ae9 0x51566f 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549576\n","  0       0        2620.00        1510.88   1394.70      51.89    0.29    0.18    0.83    0.26\n","  2     200     1112682.94      363497.72  132867.07      56.68   57.00   68.31   48.90    0.57\n","  4     400      196324.02      268497.34  41163.76      58.34   69.55   74.07   65.54    0.64\n","  6     600       49344.95      133675.26  25330.22      80.76   74.71   76.47   73.03    0.78\n","  9     800       58921.27       81628.67  18122.93      84.39   76.97   78.87   75.15    0.81\n"," 11    1000       75348.14       59422.65  14512.71      87.43   79.17   79.59   78.75    0.83\n"," 13    1200       46897.01       44602.09  11247.13      89.14   79.00   80.65   77.42    0.84\n"," 16    1400       25497.12       33951.15   7702.35      90.04   78.49   78.73   78.25    0.84\n"," 18    1600       26043.57       25661.94   6084.30      90.95   79.41   79.59   79.22    0.85\n"," 20    1800       13994.57       20201.44   4569.91      91.26   79.81   78.92   80.73    0.86\n"," 22    2000       10786.47       16178.63   3487.17      91.77   80.01   79.31   80.73    0.86\n"," 25    2200       13093.40       12967.47   2649.06      92.00   79.17   78.42   79.94    0.86\n"," 27    2400        7888.04       10429.55   2110.72      92.33   79.65   79.25   80.05    0.86\n"," 29    2600        5117.28        8247.77   1611.25      92.51   80.19   80.80   79.58    0.86\n"," 32    2800       35961.40        6577.52   1479.22      92.62   80.09   80.65   79.55    0.86\n"," 34    3000        3346.78        5102.62   1053.41      92.68   79.73   79.37   80.09    0.86\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_bert_uncased.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_uncased',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# in this case, since model uses lemmas, spacy-lookups-data should be installed\n","!pip install spacy-lookups-data\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train -g 0 --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29197,"status":"ok","timestamp":1654790482072,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"5VPflvULMSou","outputId":"5807bc01-7254-489d-ecdf-3b40248f6118"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_uncased/model-best_eval/’: File exists\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     100.00\n","LEMMA   92.39 \n","NER P   79.08 \n","NER R   79.53 \n","NER F   79.30 \n","SPEED   3688  \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","          P        R        F\n","p_    26.32    27.78    27.03\n","n_    37.35    41.89    39.49\n","pf    90.56    94.17    92.33\n","pm    63.64    87.50    73.68\n","ps    86.73    89.93    88.30\n","gc    81.98    77.78    79.82\n","oa    77.23    72.38    74.73\n","if    53.25    61.19    56.94\n","gu    75.30    77.64    76.45\n","ty    97.08    98.52    97.79\n","mn    43.48    37.04    40.00\n","oe    79.55    72.92    76.09\n","or    50.00    50.00    50.00\n","ic    73.39    56.88    64.08\n","io    63.33    58.46    60.80\n","op    71.43    64.10    67.57\n","g_    66.67    33.33    44.44\n","th    96.72    95.68    96.20\n","no    70.97    66.67    68.75\n","ia    38.46    32.26    35.09\n","nc    75.94    94.84    84.34\n","gr    52.63    47.62    50.00\n","pc    77.78    80.77    79.25\n","gs    68.75    68.75    68.75\n","ah    81.82    90.00    85.71\n","az   100.00   100.00   100.00\n","at    88.89    96.00    92.31\n","gt    50.00   100.00    66.67\n","pd    90.00   100.00    94.74\n","td   100.00    96.55    98.25\n","tm    90.48    96.61    93.44\n","gh    80.00    80.00    80.00\n","nb    93.75    51.72    66.67\n","gq    47.06    44.44    45.71\n","om    96.55    96.55    96.55\n","gl    50.00    60.00    54.55\n","me   100.00    87.50    93.33\n","ms    66.67    80.00    72.73\n","o_    52.38    57.89    55.00\n","ni    55.00    68.75    61.11\n","ns   100.00    40.00    57.14\n","na   100.00    62.50    76.92\n","tf   100.00   100.00   100.00\n","i_     0.00     0.00     0.00\n","\n","\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_uncased/model-best_eval\n","\u001b[38;5;2m✔ Saved results to\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_uncased/model-best_eval/eval.json\u001b[0m\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_bert_uncased.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_uncased',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate -g 0 $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"hSzS4imekFVJ"},"source":["**GPU bert-base-multilingual-cased**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obrTNvU1kHcZ","outputId":"60eeed7c-625d-4f76-cef3-5f8b0ddcd70d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy-lookups-data\n","  Downloading spacy_lookups_data-1.0.3-py2.py3-none-any.whl (98.5 MB)\n","\u001b[K     |████████████████████████████████| 98.5 MB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy-lookups-data) (57.4.0)\n","Installing collected packages: spacy-lookups-data\n","Successfully installed spacy-lookups-data-1.0.3\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-05 11:18:01,175] [INFO] Set up nlp object from config\n","[2022-06-05 11:18:01,185] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-05 11:18:01,186] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","[2022-06-05 11:18:01,186] [INFO] Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\n","[2022-06-05 11:18:01,191] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm', 'lemma_lookup']\n","[2022-06-05 11:18:01,392] [INFO] Added vocab lookups: lexeme_norm, lemma_lookup\n","[2022-06-05 11:18:01,392] [INFO] Created vocabulary\n","[2022-06-05 11:18:01,393] [INFO] Finished initializing nlp object\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 27.8kB/s]\n","Downloading: 100% 625/625 [00:00<00:00, 729kB/s]\n","Downloading: 100% 972k/972k [00:00<00:00, 2.64MB/s]\n","Downloading: 100% 1.87M/1.87M [00:00<00:00, 4.47MB/s]\n","Downloading: 100% 681M/681M [00:16<00:00, 43.3MB/s]\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-06-05 11:18:44,182] [INFO] Initialized pipeline components: ['transformer', 'trainable_lemmatizer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-05 11:18:44,192] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-05 11:18:44,193] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS TRAIN...  LOSS NER  LEMMA_ACC  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  -------------  --------  ---------  ------  ------  ------  ------\n","tcmalloc: large alloc 1422999552 bytes == 0xf1d5c000 @  0x7f7caed6d2a4 0x7f7ca3b07f93 0x7f7ca3b09a5d 0x7f7ca3b06235 0x7f7ca3b069de 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x548ae9 0x51566f 0x593dd7 0x511e2c 0x549576 0x593fce 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x548ae9 0x51566f\n","tcmalloc: large alloc 1430831104 bytes == 0x1714b6000 @  0x7f7caed6d2a4 0x7f7ca3b07f93 0x7f7ca3b08120 0x7f7ca3b08120 0x7f7ca3b09a5d 0x7f7ca3b06235 0x7f7ca3b069de 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x548ae9 0x51566f 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x548ae9 0x51566f 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549576\n","  0       0        4344.64        1510.88   1420.86      51.89    0.28    0.16    0.94    0.26\n","tcmalloc: large alloc 1422999552 bytes == 0xf1d5c000 @  0x7f7caed6d2a4 0x7f7ca3b07f93 0x7f7ca3b09a5d 0x7f7ca3b06235 0x7f7ca3b069de 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x548ae9 0x51566f 0x593dd7 0x511e2c 0x549576 0x593fce 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x593fce 0x5118f8 0x593dd7 0x548ae9 0x51566f\n","  2     200      951498.29      363346.25  131171.11      56.68   53.62   56.89   50.70    0.55\n","  4     400      120680.12      262991.33  40422.15      59.05   69.62   70.91   68.38    0.64\n","  6     600       68621.44      134385.62  26087.60      80.09   76.84   77.98   75.73    0.78\n","  9     800       51596.70       78402.27  17009.80      86.52   79.57   79.96   79.19    0.83\n"," 11    1000       31069.90       51158.99  13038.05      90.10   80.29   79.82   80.77    0.85\n"," 13    1200       20754.14       34386.17   9887.37      91.75   80.77   80.99   80.55    0.86\n"," 16    1400       14539.55       24111.17   7104.74      92.63   81.16   80.89   81.42    0.87\n"," 18    1600        9392.83       17701.76   5040.01      93.52   80.87   80.30   81.45    0.87\n"," 20    1800       10851.38       13379.60   3942.48      93.87   80.47   79.79   81.17    0.87\n"," 22    2000       10842.36       10117.33   2923.81      94.21   81.61   80.49   82.75    0.88\n"," 25    2200       18474.94        7511.15   2326.50      94.34   80.44   78.55   82.43    0.87\n"," 27    2400        3757.67        5600.60   1725.63      94.48   81.73   80.93   82.54    0.88\n"," 29    2600        7452.32        4166.79   1434.80      94.41   81.12   80.19   82.07    0.88\n"," 32    2800        3962.21        3229.14   1177.17      94.53   80.97   79.13   82.90    0.88\n"," 34    3000        2203.86        2299.72    918.12      94.67   81.67   81.28   82.07    0.88\n"," 36    3200        5306.63        1691.63    984.22      94.62   81.14   79.62   82.72    0.88\n"," 38    3400        1838.13        1342.14    725.00      94.70   81.84   80.87   82.82    0.88\n"," 41    3600        1947.26        1091.50    724.63      94.70   81.97   80.19   83.83    0.88\n"," 43    3800        1529.04         926.83    622.19      94.80   81.53   80.66   82.43    0.88\n"," 45    4000        1159.25         751.44    532.42      94.81   81.94   80.76   83.15    0.88\n"," 48    4200        1201.47         769.28    528.32      94.73   82.63   81.70   83.58    0.89\n"," 50    4400        1052.40         681.64    486.08      94.77   82.62   81.17   84.12    0.89\n"," 52    4600        3055.87         655.31    537.76      94.84   82.06   80.29   83.90    0.88\n"," 54    4800        1496.54         543.17    498.53      94.76   81.83   79.90   83.87    0.88\n"," 57    5000        1090.76         509.34    449.90      94.78   81.59   79.73   83.54    0.88\n"," 59    5200        1142.18         505.80    458.13      94.84   82.79   81.03   84.62    0.89\n"," 61    5400         910.38         443.59    371.10      94.77   81.90   80.12   83.76    0.88\n"," 64    5600        3840.29         443.82    418.83      94.84   81.07   80.50   81.63    0.88\n"," 66    5800        1186.60         431.03    410.25      94.79   81.14   79.33   83.04    0.88\n"," 68    6000        1038.86         463.28    358.99      94.78   81.75   80.70   82.82    0.88\n"," 70    6200        1064.35         394.16    375.51      94.74   81.18   79.77   82.64    0.88\n"," 73    6400         964.37         411.91    374.56      94.84   81.78   80.69   82.90    0.88\n"," 75    6600        1335.08         364.74    384.45      94.88   82.06   81.06   83.08    0.88\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_bert_cased.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# in this case, since model uses lemmas, spacy-lookups-data should be installed\n","!pip install spacy-lookups-data\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train -g 0 --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36835,"status":"ok","timestamp":1654790616888,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"SYNJxxBGM4aL","outputId":"e3786780-7001-42e6-f787-69740654c3fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     100.00\n","LEMMA   94.43 \n","NER P   78.76 \n","NER R   82.89 \n","NER F   80.77 \n","SPEED   6543  \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","          P        R        F\n","oa    80.17    81.17    80.67\n","ps    86.84    92.38    89.52\n","n_    33.94    50.00    40.44\n","pf    89.74    93.87    91.75\n","pm    66.67    75.00    70.59\n","gc    87.04    80.34    83.56\n","ic    73.19    63.12    67.79\n","if    55.13    64.18    59.31\n","gu    69.42    88.82    77.93\n","ty    95.04    99.26    97.10\n","mn    40.54    55.56    46.88\n","p_    29.03    25.00    26.87\n","io    75.38    75.38    75.38\n","op    66.67    66.67    66.67\n","g_    66.67    33.33    44.44\n","th    95.19    96.22    95.70\n","no    75.00    72.73    73.85\n","oe    80.00    66.67    72.73\n","nc    77.82    90.61    83.73\n","gq    61.54    44.44    51.61\n","gr    58.33    66.67    62.22\n","ia    66.67    32.26    43.48\n","pc    76.67    88.46    82.14\n","gs    81.25    81.25    81.25\n","ah    90.00    90.00    90.00\n","az    88.89    80.00    84.21\n","at    88.46    92.00    90.20\n","pd    90.00   100.00    94.74\n","td    98.21    94.83    96.49\n","tm    90.48    96.61    93.44\n","gh    66.67    80.00    72.73\n","nb    87.50    72.41    79.25\n","ns    52.63   100.00    68.97\n","om    96.55    96.55    96.55\n","me   100.00   100.00   100.00\n","gt    66.67   100.00    80.00\n","gl    71.43    50.00    58.82\n","ms    60.00    60.00    60.00\n","o_    40.91    47.37    43.90\n","ni    56.52    81.25    66.67\n","or    30.77    50.00    38.10\n","na    66.67    75.00    70.59\n","tf   100.00   100.00   100.00\n","i_     0.00     0.00     0.00\n","\n","\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/model-best_eval\n","\u001b[38;5;2m✔ Saved results to\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/model-best_eval/eval.json\u001b[0m\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_bert_cased.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate -g 0 $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"cgoKC-r8cRSt"},"source":["**GPU small-e-czech**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_dWQchfnKw5C","outputId":"3559fd8f-4dc1-4945-f104-ea12b05f4de8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy-lookups-data in /usr/local/lib/python3.7/dist-packages (1.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy-lookups-data) (57.4.0)\n","mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/models/GPU_small_e_czech’: File exists\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_small_e_czech\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-05 08:42:15,380] [INFO] Set up nlp object from config\n","[2022-06-05 08:42:15,390] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-05 08:42:15,391] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","[2022-06-05 08:42:15,391] [INFO] Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\n","[2022-06-05 08:42:15,396] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm', 'lemma_lookup']\n","[2022-06-05 08:42:15,594] [INFO] Added vocab lookups: lexeme_norm, lemma_lookup\n","[2022-06-05 08:42:15,594] [INFO] Created vocabulary\n","[2022-06-05 08:42:15,595] [INFO] Finished initializing nlp object\n","Downloading: 100% 24.0/24.0 [00:00<00:00, 24.6kB/s]\n","Downloading: 100% 410/410 [00:00<00:00, 590kB/s]\n","Downloading: 100% 229k/229k [00:00<00:00, 2.78MB/s]\n","Downloading: 100% 51.7M/51.7M [00:01<00:00, 35.3MB/s]\n","Some weights of the model checkpoint at Seznam/small-e-czech were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-06-05 08:42:38,935] [INFO] Initialized pipeline components: ['transformer', 'trainable_lemmatizer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-05 08:42:38,945] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-05 08:42:38,946] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS TRAIN...  LOSS NER  LEMMA_ACC  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  -------------  --------  ---------  ------  ------  ------  ------\n","  0       0        2135.65        1510.88   1489.91      51.89    1.18    0.68    4.29    0.27\n","  2     200     1889514.22      364603.13  323936.21      56.68    0.00    0.00    0.00    0.28\n","  4     400      141566.89      358138.68  89125.32      56.68   37.74   64.63   26.65    0.47\n","  6     600      212283.29      346926.39  54428.73      56.68   48.39   68.49   37.41    0.53\n","  9     800      346830.05      302755.45  50522.46      56.68   52.04   65.98   42.96    0.54\n"," 11    1000      364154.08      227650.05  49091.01      56.77   52.42   60.89   46.02    0.55\n"," 13    1200      160290.79      186815.68  41641.38      59.65   55.59   65.35   48.36    0.58\n"," 16    1400      112999.91      167173.35  38210.20      65.33   56.88   65.68   50.16    0.61\n"," 18    1600      159904.27      151803.54  36596.02      70.31   57.22   60.52   54.27    0.64\n"," 20    1800      333566.74      135383.62  36931.69      74.64   57.45   60.62   54.59    0.66\n"," 22    2000      223070.20      121985.41  35564.74      76.94   60.17   66.38   55.02    0.69\n"," 25    2200      176519.51      110707.34  31544.94      78.87   61.67   65.22   58.48    0.70\n"," 27    2400      171341.43      102538.29  30178.60      79.87   62.95   67.62   58.88    0.71\n"," 29    2600      250865.40       95067.74  28399.44      80.75   63.52   67.44   60.03    0.72\n"," 32    2800      286903.73       90134.09  28592.07      81.30   65.03   69.76   60.89    0.73\n"," 34    3000      330707.18       85087.12  26584.37      82.11   64.93   67.71   62.37    0.74\n"," 36    3200      305103.43       80998.07  25889.95      82.61   65.93   68.33   63.70    0.74\n"," 38    3400      344905.01       76794.70  24477.29      83.18   65.54   67.53   63.67    0.74\n"," 41    3600      218317.52       72288.08  23217.74      83.74   66.36   67.55   65.21    0.75\n"," 43    3800      165153.94       68843.67  21214.17      84.51   66.63   68.15   65.18    0.76\n"," 45    4000      245614.18       65585.87  21125.07      84.99   67.21   68.16   66.29    0.76\n"," 48    4200      253321.04       62685.56  20034.23      85.57   67.41   67.99   66.83    0.76\n"," 50    4400      169121.23       59606.37  19100.45      86.04   67.59   68.44   66.76    0.77\n"," 52    4600      204705.96       57257.55  18467.14      86.31   67.74   69.90   65.72    0.77\n"," 54    4800      202931.97       54915.57  17792.79      86.70   68.66   70.08   67.30    0.78\n"," 57    5000      141648.21       52194.87  16589.87      87.07   68.58   68.90   68.28    0.78\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_small_e_czech.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_small_e_czech',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# in this case, since model uses lemmas, spacy-lookups-data should be installed\n","!pip install spacy-lookups-data\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train -g 0 --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20759,"status":"ok","timestamp":1654790637639,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"N1hwhOnUM6WC","outputId":"237e294b-88c5-4b38-a4d0-b569679cb046"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/models/GPU_small_e_czech/model-best_eval/’: File exists\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     100.00\n","LEMMA   86.82 \n","NER P   66.39 \n","NER R   66.28 \n","NER F   66.34 \n","SPEED   18101 \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","         P       R       F\n","ps   78.45   82.31   80.34\n","ty   81.76   96.30   88.44\n","gu   59.32   65.22   62.13\n","pf   81.92   86.20   84.01\n","gr   63.64   33.33   43.75\n","ic   37.20   38.12   37.65\n","gc   69.05   74.36   71.60\n","oa   42.86   37.66   40.09\n","p_   11.11    8.33    9.52\n","mn   33.33   18.52   23.81\n","pm    0.00    0.00    0.00\n","op   38.00   48.72   42.70\n","o_   25.00    5.26    8.70\n","if   25.32   29.85   27.40\n","gq   44.44   22.22   29.63\n","io   37.18   44.62   40.56\n","g_    0.00    0.00    0.00\n","th   91.35   91.35   91.35\n","nc   72.97   88.73   80.08\n","oe   65.00   81.25   72.22\n","ia    0.00    0.00    0.00\n","pc   86.36   73.08   79.17\n","gs   52.63   31.25   39.22\n","ah   68.18   75.00   71.43\n","az   81.82   90.00   85.71\n","at   74.07   80.00   76.92\n","n_   21.21   18.92   20.00\n","gt   50.00   25.00   33.33\n","pd   88.89   88.89   88.89\n","td   93.10   93.10   93.10\n","tm   86.57   98.31   92.06\n","gh    0.00    0.00    0.00\n","ns   30.00   30.00   30.00\n","no   63.64   42.42   50.91\n","om   93.10   93.10   93.10\n","me   93.33   87.50   90.32\n","gl    0.00    0.00    0.00\n","ms    0.00    0.00    0.00\n","na   66.67   25.00   36.36\n","nb   76.00   65.52   70.37\n","ni   45.00   56.25   50.00\n","or   20.00   12.50   15.38\n","tf    0.00    0.00    0.00\n","i_    0.00    0.00    0.00\n","\n","\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_small_e_czech/model-best_eval\n","\u001b[38;5;2m✔ Saved results to\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_small_e_czech/model-best_eval/eval.json\u001b[0m\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_small_e_czech.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_small_e_czech',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate -g 0 $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"DtNZ1k23gZU3"},"source":["**GPU RobeCzech**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1697223,"status":"ok","timestamp":1654604024819,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"cLO1cNGUgP4a","outputId":"7f890c39-970f-475d-ca85-c289eda1071a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spacy-lookups-data\n","  Downloading spacy_lookups_data-1.0.3-py2.py3-none-any.whl (98.5 MB)\n","\u001b[K     |████████████████████████████████| 98.5 MB 101 kB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy-lookups-data) (57.4.0)\n","Installing collected packages: spacy-lookups-data\n","Successfully installed spacy-lookups-data-1.0.3\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_robeczech\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-07 11:45:51,869] [INFO] Set up nlp object from config\n","[2022-06-07 11:45:51,878] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-07 11:45:51,879] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","[2022-06-07 11:45:51,879] [INFO] Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\n","[2022-06-07 11:45:51,884] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm', 'lemma_lookup']\n","[2022-06-07 11:45:52,074] [INFO] Added vocab lookups: lexeme_norm, lemma_lookup\n","[2022-06-07 11:45:52,074] [INFO] Created vocabulary\n","[2022-06-07 11:45:52,075] [INFO] Finished initializing nlp object\n","Downloading: 100% 184/184 [00:00<00:00, 192kB/s]\n","Downloading: 100% 516/516 [00:00<00:00, 479kB/s]\n","Downloading: 100% 1.01M/1.01M [00:01<00:00, 796kB/s]\n","Downloading: 100% 587k/587k [00:01<00:00, 564kB/s]\n","Downloading: 100% 483M/483M [00:29<00:00, 17.2MB/s]\n","Some weights of the model checkpoint at ufal/robeczech-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-06-07 11:47:02,146] [INFO] Initialized pipeline components: ['transformer', 'trainable_lemmatizer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-07 11:47:02,156] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-07 11:47:02,157] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS TRAIN...  LOSS NER  LEMMA_ACC  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  -------------  --------  ---------  ------  ------  ------  ------\n","The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n","The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n","  0       0       37875.16        1510.88   1000.77      51.89    0.00    0.00    0.00    0.26\n","The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n","The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n","  2     200     2221228.58      364432.55  164381.54      56.68    0.00    0.00    0.00    0.28\n","The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n","The OrderedVocab you are attempting to save contains a hole for index 51959, your vocabulary could be corrupted !\n","\n","Aborted!\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/__main__.py\", line 4, in <module>\n","    setup_cli()\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/_util.py\", line 71, in setup_cli\n","    command(prog_name=COMMAND)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n","    return self.main(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n","    rv = self.invoke(ctx)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1259, in invoke\n","    return _process_result(sub_ctx.command.invoke(sub_ctx))\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n","    return ctx.invoke(self.callback, **ctx.params)\n","  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n","    return callback(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 500, in wrapper\n","    return callback(**use_params)  # type: ignore\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/evaluate.py\", line 50, in evaluate_cli\n","    silent=False,\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/evaluate.py\", line 76, in evaluate\n","    nlp = util.load_model(model)\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 422, in load_model\n","    return load_model_from_path(Path(name), **kwargs)  # type: ignore[arg-type]\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 491, in load_model_from_path\n","    return nlp.from_disk(model_path, exclude=exclude, overrides=overrides)\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/language.py\", line 2043, in from_disk\n","    util.from_disk(path, deserializers, exclude)  # type: ignore[arg-type]\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1303, in from_disk\n","    reader(path / key)\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/language.py\", line 2038, in <lambda>\n","    p, exclude=[\"vocab\"]\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy_transformers/pipeline_component.py\", line 420, in from_disk\n","    util.from_disk(path, deserialize, exclude)\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy/util.py\", line 1303, in from_disk\n","    reader(path / key)\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy_transformers/pipeline_component.py\", line 394, in load_model\n","    self.model.from_bytes(mfile.read())\n","  File \"/usr/local/lib/python3.7/dist-packages/thinc/model.py\", line 594, in from_bytes\n","    return self.from_dict(msg)\n","  File \"/usr/local/lib/python3.7/dist-packages/thinc/model.py\", line 632, in from_dict\n","    node.shims[i].from_bytes(shim_bytes)\n","  File \"/usr/local/lib/python3.7/dist-packages/spacy_transformers/layers/hf_shim.py\", line 92, in from_bytes\n","    tokenizer = AutoTokenizer.from_pretrained(str(temp_dir.absolute()))\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\", line 555, in from_pretrained\n","    return tokenizer_class.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\", line 1791, in from_pretrained\n","    **kwargs,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py\", line 1929, in _from_pretrained\n","    tokenizer = cls(*init_inputs, **init_kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/tokenization_roberta_fast.py\", line 184, in __init__\n","    **kwargs,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_fast.py\", line 109, in __init__\n","    fast_tokenizer = TokenizerFast.from_file(fast_tokenizer_file)\n","Exception: data did not match any variant of untagged enum ModelWrapper at line 103792 column 3\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_robeczech.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_robeczech',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# in this case, since model uses lemmas, spacy-lookups-data should be installed\n","!pip install spacy-lookups-data\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train -g 0 --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckvsVFz6M78g"},"outputs":[],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_robeczech.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_robeczech',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate -g 0 $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"cA4Q3T3HhaBj"},"source":["**GPU Czert B-based cased**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"chlQ8Kmfhhxg","outputId":"59586a33-5045-47f3-abf9-7aed8a4980cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy-lookups-data in /usr/local/lib/python3.7/dist-packages (1.0.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy-lookups-data) (57.4.0)\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_czert_b_based\u001b[0m\n","\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2022-06-07 12:15:16,754] [INFO] Set up nlp object from config\n","[2022-06-07 12:15:16,763] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-07 12:15:16,764] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","[2022-06-07 12:15:16,764] [INFO] Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\n","[2022-06-07 12:15:16,769] [DEBUG] Loading lookups from spacy-lookups-data: ['lexeme_norm', 'lemma_lookup']\n","[2022-06-07 12:15:16,976] [INFO] Added vocab lookups: lexeme_norm, lemma_lookup\n","[2022-06-07 12:15:16,976] [INFO] Created vocabulary\n","[2022-06-07 12:15:16,977] [INFO] Finished initializing nlp object\n","Downloading: 100% 161/161 [00:00<00:00, 168kB/s]\n","Downloading: 100% 675/675 [00:00<00:00, 656kB/s]\n","Downloading: 100% 209k/209k [00:00<00:00, 329kB/s] \n","Downloading: 100% 112/112 [00:00<00:00, 106kB/s]\n","Downloading: 100% 420M/420M [00:30<00:00, 14.3MB/s]\n","Some weights of the model checkpoint at UWB-AIR/Czert-B-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[2022-06-07 12:16:11,987] [INFO] Initialized pipeline components: ['transformer', 'trainable_lemmatizer', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","[2022-06-07 12:16:11,998] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/dev_transformed_clean.spacy\n","[2022-06-07 12:16:12,000] [DEBUG] Loading corpus from path: /content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/train_transformed_clean.spacy\n","\u001b[38;5;4mℹ Pipeline: ['transformer', 'trainable_lemmatizer', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n","E    #       LOSS TRANS...  LOSS TRAIN...  LOSS NER  LEMMA_ACC  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  -------------  -------------  --------  ---------  ------  ------  ------  ------\n","  0       0        2617.35        1510.88   1484.93      51.89    0.22    0.13    0.68    0.26\n","  2     200     1381222.42      361453.11  138106.64      56.68   54.80   72.91   43.90    0.56\n","  4     400      266384.25      210980.88  44268.53      76.97   68.30   71.42   65.43    0.73\n","  6     600       95589.91       84448.05  25835.81      86.03   71.23   75.41   67.48    0.79\n","  9     800       39596.49       50865.23  17114.81      89.81   76.03   74.93   77.17    0.83\n"," 11    1000       70639.61       33557.02  12792.56      91.32   78.10   79.59   76.67    0.85\n"," 13    1200       23000.88       23875.21   8529.47      92.28   77.74   78.80   76.70    0.85\n"," 16    1400       16702.72       17049.68   5520.67      92.91   78.74   78.94   78.54    0.86\n"," 18    1600        6787.35       12055.38   3463.87      93.36   80.02   78.47   81.63    0.87\n"," 20    1800        4238.22        8785.42   2260.78      93.55   79.26   78.11   80.45    0.86\n"," 22    2000       76471.37        6205.06   1841.31      93.81   78.72   78.19   79.26    0.86\n"," 25    2200       14313.96        4315.62   1322.31      93.88   78.24   78.02   78.47    0.86\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_czert_b_based.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_czert_b_based',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# in this case, since model uses lemmas, spacy-lookups-data should be installed\n","!pip install spacy-lookups-data\n","\n","# create model directory\n","!mkdir $model_dir\n","\n","# train model\n","!python -m spacy train -g 0 --verbose $cfg --output $model_dir\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26744,"status":"ok","timestamp":1654790686509,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"etbi8gldYIZE","outputId":"c9620b22-8b9a-4b77-9bbe-e6652663119f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n","\u001b[1m\n","================================== Results ==================================\u001b[0m\n","\n","TOK     100.00\n","LEMMA   93.96 \n","NER P   77.47 \n","NER R   81.12 \n","NER F   79.25 \n","SPEED   8429  \n","\n","\u001b[1m\n","=============================== NER (per type) ===============================\u001b[0m\n","\n","          P        R        F\n","gs    58.62    53.12    55.74\n","ps    84.84    92.14    88.34\n","n_    48.28    56.76    52.17\n","pf    90.18    92.94    91.54\n","pm    83.33    62.50    71.43\n","gc    86.11    79.49    82.67\n","oa    68.53    66.53    67.52\n","g_    50.00    33.33    40.00\n","mn    60.00    44.44    51.06\n","ty    93.66    98.52    96.03\n","gu    71.43    83.85    77.14\n","p_    19.05    22.22    20.51\n","if    59.15    62.69    60.87\n","op    51.72    76.92    61.86\n","oe    80.00    91.67    85.44\n","or    30.00    37.50    33.33\n","io    67.14    72.31    69.63\n","ic    70.63    63.12    66.67\n","th    97.81    96.76    97.28\n","no    70.59    72.73    71.64\n","nc    77.78    92.02    84.30\n","gr    60.87    66.67    63.64\n","ia    42.86    29.03    34.62\n","pc    85.19    88.46    86.79\n","ah    72.73    80.00    76.19\n","az    70.00    70.00    70.00\n","at    82.14    92.00    86.79\n","gl    33.33    40.00    36.36\n","gt    50.00   100.00    66.67\n","pd    90.00   100.00    94.74\n","nb    83.33    68.97    75.47\n","td   100.00    98.28    99.13\n","tm    92.06    98.31    95.08\n","gh    71.43   100.00    83.33\n","ns    66.67    60.00    63.16\n","gq    53.85    38.89    45.16\n","om    96.55    96.55    96.55\n","me    93.33    87.50    90.32\n","o_    47.37    47.37    47.37\n","i_     0.00     0.00     0.00\n","ni    63.16    75.00    68.57\n","ms    44.44    80.00    57.14\n","na    77.78    87.50    82.35\n","tf   100.00   100.00   100.00\n","\n","\u001b[38;5;2m✔ Generated 25 parses as HTML\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_czert_b_based/model-best_eval\n","\u001b[38;5;2m✔ Saved results to\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_czert_b_based/model-best_eval/eval.json\u001b[0m\n"]}],"source":["set_temp_train_variables('/content/DP/src/spacy_config_files/GPU_czert_b_based.cfg',\n","                         '/content/drive/MyDrive/PIIAnonymizer/models/GPU_czert_b_based',\n","                         '/content/drive/MyDrive/PIIAnonymizer/datasets/CNEC2.0/lemmas/spacy/test_transformed_clean.spacy')\n","\n","# evaluate on test dataset\n","!mkdir $model_eval_path\n","!python -m spacy evaluate -g 0 $model_best_path $test_dataset -o $model_eval_path_json -dp $model_eval_path"]},{"cell_type":"markdown","metadata":{"id":"SBhSIV0jQ9X_"},"source":["# Presidio evaluation\n","\n","In this part, PIIAnonymizer tool is created, using Presidio SDK, and then evaluated on a custom evaluation dataset.\n","\n","Please note, that custom recognizers' implementation as well as presidio setup is a part of the Streamlit GUI application, used in the last section. This code was copied to this notebook only to evaluate PIIAnonymizer tool on the evaluation dataset."]},{"cell_type":"markdown","metadata":{"id":"ecxMuhh6SPPT"},"source":["Install required presidio modules"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16040,"status":"ok","timestamp":1654882049201,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"uuKnaGMASOYd","outputId":"535a956c-e45d-47bf-f95b-647eb933229f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting presidio_analyzer\n","  Downloading presidio_analyzer-2.2.28-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting tldextract\n","  Downloading tldextract-3.3.0-py3-none-any.whl (93 kB)\n","\u001b[K     |████████████████████████████████| 93 kB 2.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from presidio_analyzer) (2019.12.20)\n","Collecting phonenumbers>=8.12\n","  Downloading phonenumbers-8.12.49-py2.py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 61.7 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from presidio_analyzer) (3.3.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from presidio_analyzer) (6.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (21.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (3.0.6)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (2.0.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (57.4.0)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (0.4.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (0.6.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (2.4.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (2.11.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (2.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (4.64.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (1.21.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (1.0.7)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (3.0.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (8.0.17)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (1.8.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (3.3.0)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (4.1.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio_analyzer) (0.9.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.0->presidio_analyzer) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.2.0->presidio_analyzer) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.0->presidio_analyzer) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->presidio_analyzer) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->presidio_analyzer) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->presidio_analyzer) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.0->presidio_analyzer) (2022.5.18.1)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.2.0->presidio_analyzer) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.0->presidio_analyzer) (2.0.1)\n","Collecting requests-file>=1.4\n","  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->presidio_analyzer) (3.7.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from requests-file>=1.4->tldextract->presidio_analyzer) (1.15.0)\n","Installing collected packages: requests-file, tldextract, phonenumbers, presidio-analyzer\n","Successfully installed phonenumbers-8.12.49 presidio-analyzer-2.2.28 requests-file-1.5.1 tldextract-3.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting presidio_anonymizer\n","  Downloading presidio_anonymizer-2.2.28-py3-none-any.whl (25 kB)\n","Collecting pycryptodome>=3.10.1\n","  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 19.8 MB/s \n","\u001b[?25hInstalling collected packages: pycryptodome, presidio-anonymizer\n","Successfully installed presidio-anonymizer-2.2.28 pycryptodome-3.14.1\n"]}],"source":["!pip install presidio_analyzer\n","!pip install presidio_anonymizer"]},{"cell_type":"markdown","metadata":{"id":"fm0Ofs0YMH6Z"},"source":["**CPU version**\n","\n","Create custom analyzer engine for a CPU session"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1654876770424,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"5UVwtHV_Hccd"},"outputs":[],"source":["import json\n","from json import JSONEncoder\n","import pandas as pd\n","from presidio_analyzer import AnalyzerEngine\n","from presidio_anonymizer import AnonymizerEngine\n","import spacy\n","\n","\n","nlp = spacy.load('/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/model-best')\n","\n","import logging\n","from typing import Optional, List, Tuple, Set\n","\n","from presidio_analyzer import (\n","    RecognizerResult,\n","    LocalRecognizer,\n","    AnalysisExplanation,\n",")\n","\n","logger = logging.getLogger(\"presidio-analyzer\")\n","\n","# this custom spacy recognizer is based on https://github.com/microsoft/presidio/blob/main/presidio-analyzer/presidio_analyzer/predefined_recognizers/spacy_recognizer.py\n","class SpacyRecognizerCustom(LocalRecognizer):\n","    \"\"\"\n","    Recognize PII entities using a spaCy NLP model.\n","    This recognizer extract entities from NlpArtifacts and align their types with Presidio.\n","    :param supported_language: Language this recognizer supports\n","    :param supported_entities: The entities this recognizer can detect\n","    :param ner_strength: Default confidence for NER prediction\n","    :param check_label_groups: Tuple containing Presidio entity names\n","    and spaCy entity names, for verifying that the right entity\n","    is translated into a Presidio entity.\n","    \"\"\"\n","\n","    ENTITIES = [\n","        \"PERSON\",\n","        \"EMAIL_ADDRESS\",\n","        \"LOGIN_NICK\",\n","        \"INSTITUTION\",\n","        \"PHONE_NUM\",\n","        \"MEDIA_NAME\",\n","        \"NUMBER_EXPR\",\n","        \"LOCATION\",\n","        \"PRODUCT\",\n","        \"DATE_TIME\",\n","        \"OTHER\"\n","    ]\n","\n","    DEFAULT_EXPLANATION = \"Identified as {} by Spacy's Named Entity Recognition\"\n","\n","    CHECK_LABEL_GROUPS = [\n","        ({\"PERSON\"}, {\"pd\", \"pf\", \"pm\", \"ps\"}),\n","        ({\"EMAIL_ADDRESS\"}, {\"me\"}),\n","        ({\"LOGIN_NICK\"}, {\"p_\"}),\n","        ({\"iNSTITUTION\"}, {\"ia\", \"ic\", \"if\", \"io\", \"i_\"}),\n","        ({\"PHONE_NUM\"}, {\"at\"}),\n","        ({\"MEDIA_NAME\"}, {\"mn\", \"ms\"}),\n","        ({\"NUMBER_EXPR\"}, {\"nb\", \"nc\", \"ni\", \"no\", \"ns\", \"n_\"}),\n","        ({\"LOCATION\"}, {\"ah\", \"az\", \"gc\", \"gh\", \"gl\", \"gq\", \"gr\", \"gs\", \"gt\", \"gu\", \"g_\"}),\n","        ({\"PRODUCT\"}, {\"op\"}),\n","        ({\"DATE_TIME\"}, {\"td\", \"tf\", \"th\", \"tm\", \"ty\"}),\n","        ({\"OTHER\"}, {\"oa\", \"or\", \"o_\", \"pc\"})\n","    ]\n","\n","    def __init__(\n","        self,\n","        supported_language: str = \"cs\",\n","        supported_entities: Optional[List[str]] = None,\n","        ner_strength: float = 0.82,\n","        check_label_groups: Optional[Tuple[Set, Set]] = None,\n","        context: Optional[List[str]] = None,\n","    ):\n","        self.ner_strength = ner_strength\n","        self.check_label_groups = (\n","            check_label_groups if check_label_groups else self.CHECK_LABEL_GROUPS\n","        )\n","        supported_entities = supported_entities if supported_entities else self.ENTITIES\n","        super().__init__(\n","            supported_entities=supported_entities,\n","            supported_language=supported_language,\n","            context=context,\n","        )\n","\n","    def load(self) -> None:\n","        pass\n","\n","    def build_spacy_explanation(\n","        self, original_score: float, explanation: str\n","    ) -> AnalysisExplanation:\n","        explanation = AnalysisExplanation(\n","            recognizer=self.__class__.__name__,\n","            original_score=original_score,\n","            textual_explanation=explanation,\n","        )\n","        return explanation\n","\n","    def analyze(self, text, entities, nlp_artifacts=None):\n","        results = []\n","        if not nlp_artifacts:\n","            logger.warning(\"Nlp artifacts not provided...\")\n","            return results\n","\n","        ner_entities = nlp_artifacts.entities\n","\n","        for entity in entities:\n","            if entity not in self.supported_entities:\n","                continue\n","            for ent in ner_entities:\n","                if not self.__check_label(entity, ent.label_, self.check_label_groups):\n","                    continue\n","                textual_explanation = self.DEFAULT_EXPLANATION.format(ent.label_)\n","                explanation = self.build_spacy_explanation(\n","                    self.ner_strength, textual_explanation\n","                )\n","                spacy_result = RecognizerResult(\n","                    entity_type=entity,\n","                    start=ent.start_char,\n","                    end=ent.end_char,\n","                    score=self.ner_strength,\n","                    analysis_explanation=explanation,\n","                    recognition_metadata={\n","                        RecognizerResult.RECOGNIZER_NAME_KEY: self.name\n","                    },\n","                )\n","                results.append(spacy_result)\n","\n","        return results\n","\n","    @staticmethod\n","    def __check_label(\n","        entity: str, label: str, check_label_groups: Tuple[Set, Set]\n","    ) -> bool:\n","        return any(\n","            [entity in egrp and label in lgrp for egrp, lgrp in check_label_groups]\n","        )\n","\n","spacy_recognizer_custom = SpacyRecognizerCustom()\n","\n","from collections import defaultdict\n","from typing import List, Optional\n","\n","from presidio_analyzer import Pattern, PatternRecognizer\n","\n","\n","class CSRCRecognizer(PatternRecognizer):\n","    \"\"\"Recognize CS \"rodne cislo\" using regex.\n","    :param patterns: List of patterns to be used by this recognizer\n","    :param context: List of context words to increase confidence in detection\n","    :param supported_language: Language this recognizer supports\n","    :param supported_entity: The entity this recognizer can detect\n","    \"\"\"\n","\n","    PATTERNS = [\n","        Pattern(\"rodne cislo (high)\", r\"\\d{2}(0[1-9]|1[0-2]|5[1-9]|6[0-2])(0[1-9]|1[0-9]|2[0-9]|3[0-1])\\/?\\d{3,4}\", 0.5)\n","    ]\n","\n","    CONTEXT = [\n","        \"rc\",\n","        \"rodne\",\n","        \"pojistence\"\n","        \"cislo\"\n","    ]\n","\n","    def __init__(\n","        self,\n","        patterns: Optional[List[Pattern]] = None,\n","        context: Optional[List[str]] = None,\n","        supported_language: str = \"cs\",\n","        supported_entity: str = \"CS_RC\",\n","    ):\n","        patterns = patterns if patterns else self.PATTERNS\n","        context = context if context else self.CONTEXT\n","        super().__init__(\n","            supported_entity=supported_entity,\n","            patterns=patterns,\n","            context=context,\n","            supported_language=supported_language,\n","        )\n","\n","rc_recognizer = CSRCRecognizer()\n","\n","from presidio_analyzer.predefined_recognizers import CreditCardRecognizer, CryptoRecognizer, EmailRecognizer, IbanRecognizer, IpRecognizer, PhoneRecognizer, UrlRecognizer\n","\n","credit_card_recognizer = CreditCardRecognizer(supported_language=\"cs\", context=[\"kreditni\", \"debetni\", \"karta\", \"visa\", \"mastercard\", \"maestro\", \"platba\"])\n","crypto_recognizer = CryptoRecognizer(supported_language=\"cs\", context=[\"wallet\", \"btc\", \"bitcoin\", \"ethereum\", \"eth\", \"crypto\", \"kryptomena\"])\n","email_recognizer = EmailRecognizer(supported_language=\"cs\", context=[\"email\", \"mail\", \"e-mail\"])\n","iban_recognizer = IbanRecognizer(supported_language=\"cs\", context=[\"iban\", \"banka\", \"swift\", \"zahranicni\", \"transakce\", \"platba\"])\n","ip_recognizer = IpRecognizer(supported_language=\"cs\")\n","url_recognizer = UrlRecognizer(supported_language=\"cs\", supported_entity=\"DOMAIN\")\n","\n","from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n","from presidio_analyzer.nlp_engine import NlpEngineProvider\n","\n","\n","# Create configuration containing engine name and models\n","configuration = {\n","    \"nlp_engine_name\": \"spacy\",\n","    \"models\": [{\"lang_code\": \"cs\", \"model_name\": \"cs_CPU_fine_nomorph\"}],\n","}\n","\n","# Create new recognizer registry and add the custom recognizer\n","recognizer_registry = RecognizerRegistry()\n","\n","# append custom recognizers\n","recognizer_registry.add_recognizer(spacy_recognizer_custom)\n","recognizer_registry.add_recognizer(rc_recognizer)\n","\n","# append predefined universal presidio recognizers\n","recognizer_registry.add_recognizer(credit_card_recognizer)\n","recognizer_registry.add_recognizer(crypto_recognizer)\n","recognizer_registry.add_recognizer(email_recognizer)\n","recognizer_registry.add_recognizer(iban_recognizer)\n","recognizer_registry.add_recognizer(ip_recognizer)\n","\n","# Create NLP engine based on configuration\n","provider = NlpEngineProvider(nlp_configuration=configuration)\n","nlp_engine_custom = provider.create_engine()\n","\n","# Pass the created NLP engine and supported_languages to the AnalyzerEngine\n","analyzer = AnalyzerEngine(\n","    nlp_engine=nlp_engine_custom, \n","    supported_languages=[\"cs\", \"en\"],\n","    registry=recognizer_registry\n",")"]},{"cell_type":"markdown","metadata":{"id":"HmTJdKFXM9AS"},"source":["**GPU version**\n","\n","Create custom analyzer engine for a GPU session"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":18669,"status":"ok","timestamp":1654880601315,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"qwFKSzb-BsyH"},"outputs":[],"source":["import json\n","from json import JSONEncoder\n","import pandas as pd\n","from presidio_analyzer import AnalyzerEngine\n","from presidio_anonymizer import AnonymizerEngine\n","import spacy\n","\n","nlp = spacy.load('/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/model-best')\n","\n","import logging\n","from typing import Optional, List, Tuple, Set\n","\n","from presidio_analyzer import (\n","    RecognizerResult,\n","    LocalRecognizer,\n","    AnalysisExplanation,\n",")\n","\n","logger = logging.getLogger(\"presidio-analyzer\")\n","\n","# this custom spacy recognizer is based on https://github.com/microsoft/presidio/blob/main/presidio-analyzer/presidio_analyzer/predefined_recognizers/spacy_recognizer.py\n","class SpacyRecognizerCustom(LocalRecognizer):\n","    \"\"\"\n","    Recognize PII entities using a spaCy NLP model.\n","    Since the spaCy pipeline is ran by the AnalyzerEngine,\n","    this recognizer only extracts the entities from the NlpArtifacts\n","    and replaces their types to align with Presidio's.\n","    :param supported_language: Language this recognizer supports\n","    :param supported_entities: The entities this recognizer can detect\n","    :param ner_strength: Default confidence for NER prediction\n","    :param check_label_groups: Tuple containing Presidio entity names\n","    and spaCy entity names, for verifying that the right entity\n","    is translated into a Presidio entity.\n","    \"\"\"\n","\n","    ENTITIES = [\n","        \"PERSON\",\n","        \"EMAIL_ADDRESS\",\n","        \"LOGIN_NICK\",\n","        \"INSTITUTION\",\n","        \"PHONE_NUM\",\n","        \"MEDIA_NAME\",\n","        \"NUMBER_EXPR\",\n","        \"LOCATION\",\n","        \"PRODUCT\",\n","        \"DATE_TIME\",\n","        \"OTHER\"\n","    ]\n","\n","    DEFAULT_EXPLANATION = \"Identified as {} by Spacy's Named Entity Recognition\"\n","\n","    CHECK_LABEL_GROUPS = [\n","        ({\"PERSON\"}, {\"pd\", \"pf\", \"pm\", \"ps\"}),\n","        ({\"EMAIL_ADDRESS\"}, {\"me\"}),\n","        ({\"LOGIN_NICK\"}, {\"p_\"}),\n","        ({\"iNSTITUTION\"}, {\"ia\", \"ic\", \"if\", \"io\", \"i_\"}),\n","        ({\"PHONE_NUM\"}, {\"at\"}),\n","        ({\"MEDIA_NAME\"}, {\"mn\", \"ms\"}),\n","        ({\"NUMBER_EXPR\"}, {\"nb\", \"nc\", \"ni\", \"no\", \"ns\", \"n_\"}),\n","        ({\"LOCATION\"}, {\"ah\", \"az\", \"gc\", \"gh\", \"gl\", \"gq\", \"gr\", \"gs\", \"gt\", \"gu\", \"g_\"}),\n","        ({\"PRODUCT\"}, {\"op\"}),\n","        ({\"DATE_TIME\"}, {\"td\", \"tf\", \"th\", \"tm\", \"ty\"}),\n","        ({\"OTHER\"}, {\"oa\", \"or\", \"o_\", \"pc\"})\n","    ]\n","\n","    def __init__(\n","        self,\n","        supported_language: str = \"cs\",\n","        supported_entities: Optional[List[str]] = None,\n","        ner_strength: float = 0.82,\n","        check_label_groups: Optional[Tuple[Set, Set]] = None,\n","        context: Optional[List[str]] = None,\n","    ):\n","        self.ner_strength = ner_strength\n","        self.check_label_groups = (\n","            check_label_groups if check_label_groups else self.CHECK_LABEL_GROUPS\n","        )\n","        supported_entities = supported_entities if supported_entities else self.ENTITIES\n","        super().__init__(\n","            supported_entities=supported_entities,\n","            supported_language=supported_language,\n","            context=context,\n","        )\n","\n","    def load(self) -> None:\n","        pass\n","\n","    def build_spacy_explanation(\n","        self, original_score: float, explanation: str\n","    ) -> AnalysisExplanation:\n","        \"\"\"\n","        Create explanation for why this result was detected.\n","        :param original_score: Score given by this recognizer\n","        :param explanation: Explanation string\n","        :return:\n","        \"\"\"\n","        explanation = AnalysisExplanation(\n","            recognizer=self.__class__.__name__,\n","            original_score=original_score,\n","            textual_explanation=explanation,\n","        )\n","        return explanation\n","\n","    def analyze(self, text, entities, nlp_artifacts=None):\n","        results = []\n","        if not nlp_artifacts:\n","            return results\n","\n","        ner_entities = nlp_artifacts.entities\n","\n","        for entity in entities:\n","            if entity not in self.supported_entities:\n","                continue\n","            for ent in ner_entities:\n","                if not self.__check_label(entity, ent.label_, self.check_label_groups):\n","                    continue\n","                textual_explanation = self.DEFAULT_EXPLANATION.format(ent.label_)\n","                explanation = self.build_spacy_explanation(\n","                    self.ner_strength, textual_explanation\n","                )\n","                spacy_result = RecognizerResult(\n","                    entity_type=entity,\n","                    start=ent.start_char,\n","                    end=ent.end_char,\n","                    score=self.ner_strength,\n","                    analysis_explanation=explanation,\n","                    recognition_metadata={\n","                        RecognizerResult.RECOGNIZER_NAME_KEY: self.name\n","                    },\n","                )\n","                results.append(spacy_result)\n","\n","        return results\n","\n","    @staticmethod\n","    def __check_label(\n","        entity: str, label: str, check_label_groups: Tuple[Set, Set]\n","    ) -> bool:\n","        return any(\n","            [entity in egrp and label in lgrp for egrp, lgrp in check_label_groups]\n","        )\n","\n","# Create custom recognizer based on NER model NEs\n","spacy_recognizer_custom = SpacyRecognizerCustom()\n","\n","from collections import defaultdict\n","from typing import List, Optional\n","\n","from presidio_analyzer import Pattern, PatternRecognizer\n","\n","\n","class CSRCRecognizer(PatternRecognizer):\n","    \"\"\"Recognize CS \"rodne cislo\" using regex.\n","    :param patterns: List of patterns to be used by this recognizer\n","    :param context: List of context words to increase confidence in detection\n","    :param supported_language: Language this recognizer supports\n","    :param supported_entity: The entity this recognizer can detect\n","    \"\"\"\n","\n","    PATTERNS = [\n","        Pattern(\"rodne cislo (high)\", r\"\\d{2}(0[1-9]|1[0-2]|5[1-9]|6[0-2])(0[1-9]|1[0-9]|2[0-9]|3[0-1])\\/?\\d{3,4}\", 0.5)\n","    ]\n","\n","    CONTEXT = [\n","        \"rc\",\n","        \"rodne\",\n","        \"pojistence\"\n","        \"cislo\"\n","    ]\n","\n","    def __init__(\n","        self,\n","        patterns: Optional[List[Pattern]] = None,\n","        context: Optional[List[str]] = None,\n","        supported_language: str = \"cs\",\n","        supported_entity: str = \"CS_RC\",\n","    ):\n","        patterns = patterns if patterns else self.PATTERNS\n","        context = context if context else self.CONTEXT\n","        super().__init__(\n","            supported_entity=supported_entity,\n","            patterns=patterns,\n","            context=context,\n","            supported_language=supported_language,\n","        )\n","\n","rc_recognizer = CSRCRecognizer()\n","\n","from presidio_analyzer.predefined_recognizers import CreditCardRecognizer, CryptoRecognizer, EmailRecognizer, IbanRecognizer, IpRecognizer, PhoneRecognizer, UrlRecognizer\n","\n","credit_card_recognizer = CreditCardRecognizer(supported_language=\"cs\", context=[\"kreditni\", \"debetni\", \"karta\", \"visa\", \"mastercard\", \"maestro\", \"platba\"])\n","crypto_recognizer = CryptoRecognizer(supported_language=\"cs\", context=[\"wallet\", \"btc\", \"bitcoin\", \"ethereum\", \"eth\", \"crypto\", \"kryptomena\"])\n","email_recognizer = EmailRecognizer(supported_language=\"cs\", context=[\"email\", \"mail\", \"e-mail\"])\n","iban_recognizer = IbanRecognizer(supported_language=\"cs\", context=[\"iban\", \"banka\", \"swift\", \"zahranicni\", \"transakce\", \"platba\"])\n","ip_recognizer = IpRecognizer(supported_language=\"cs\")\n","url_recognizer = UrlRecognizer(supported_language=\"cs\", supported_entity=\"DOMAIN\")\n","\n","from presidio_analyzer import AnalyzerEngine, RecognizerRegistry\n","from presidio_analyzer.nlp_engine import NlpEngineProvider\n","\n","\n","# Create configuration containing engine name and models\n","configuration = {\n","    \"nlp_engine_name\": \"spacy\",\n","    \"models\": [{\"lang_code\": \"cs\", \"model_name\": \"cs_GPU_bert_cased\"}],\n","}\n","\n","# Create new recognizer registry and add the custom recognizer\n","recognizer_registry = RecognizerRegistry()\n","\n","# append custom recognizers\n","recognizer_registry.add_recognizer(spacy_recognizer_custom)\n","recognizer_registry.add_recognizer(rc_recognizer)\n","\n","# append predefined universal presidio recognizers\n","recognizer_registry.add_recognizer(credit_card_recognizer)\n","recognizer_registry.add_recognizer(crypto_recognizer)\n","recognizer_registry.add_recognizer(email_recognizer)\n","recognizer_registry.add_recognizer(iban_recognizer)\n","recognizer_registry.add_recognizer(ip_recognizer)\n","\n","# Create NLP engine based on configuration\n","provider = NlpEngineProvider(nlp_configuration=configuration)\n","nlp_engine_custom = provider.create_engine()\n","\n","# Pass the created NLP engine and supported_languages to the AnalyzerEngine\n","analyzer = AnalyzerEngine(\n","    nlp_engine=nlp_engine_custom, \n","    supported_languages=[\"cs\"],\n","    registry=recognizer_registry\n",")"]},{"cell_type":"markdown","metadata":{"id":"iYH0YpEnRAk1"},"source":["### PIIAnonymizer evaluation\n","Developed tool is evaluated through the \"presidio-research\" repo, which can be used to generate mock PII datasets or to evaluate custom recognizers"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1020,"status":"ok","timestamp":1654880602332,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"4w-ikeRlSyja","outputId":"0c9b64ee-111c-4195-f11f-70874a42b0bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n","Cloning into 'presidio-research'...\n","remote: Enumerating objects: 1022, done.\u001b[K\n","remote: Counting objects: 100% (159/159), done.\u001b[K\n","remote: Compressing objects: 100% (56/56), done.\u001b[K\n","remote: Total 1022 (delta 114), reused 109 (delta 103), pack-reused 863\u001b[K\n","Receiving objects: 100% (1022/1022), 2.01 MiB | 16.99 MiB/s, done.\n","Resolving deltas: 100% (653/653), done.\n","/content/presidio-research\n"]}],"source":["%cd /content\n","!git clone https://github.com/microsoft/presidio-research.git\n","%cd /content/presidio-research/"]},{"cell_type":"markdown","metadata":{"id":"8IZghS-_S6ky"},"source":["Install presidio-research package + dependencies"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":32076,"status":"ok","timestamp":1654880634636,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"cl1LY7DbTMm-","outputId":"f47b1947-6bd9-4ff6-8e9c-caaa5029c5e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting en_core_web_sm\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0.tar.gz (13.9 MB)\n","\u001b[K     |████████████████████████████████| 13.9 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.3.1)\n","Requirement already satisfied: numpy>=1.20.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n","Requirement already satisfied: jupyter>=1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.0.0)\n","Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.3.5)\n","Requirement already satisfied: tqdm>=4.60.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.64.0)\n","Collecting haikunator>=2.1.0\n","  Downloading haikunator-2.1.0-py2.py3-none-any.whl (4.6 kB)\n","Collecting schwifty\n","  Downloading schwifty-2022.6.0-py3-none-any.whl (204 kB)\n","\u001b[K     |████████████████████████████████| 204 kB 5.1 MB/s \n","\u001b[?25hCollecting faker>=9.6.0\n","  Downloading Faker-13.13.0-py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 55.5 MB/s \n","\u001b[?25hRequirement already satisfied: scikit_learn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.0.2)\n","Collecting pytest>=6.2.3\n","  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n","\u001b[K     |████████████████████████████████| 297 kB 66.0 MB/s \n","\u001b[?25hRequirement already satisfied: presidio_analyzer in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (2.2.28)\n","Requirement already satisfied: presidio_anonymizer in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.2.28)\n","Collecting requests>=2.25.1\n","  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n","\u001b[?25hCollecting xmltodict>=0.12.0\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Collecting python-dotenv\n","  Downloading python_dotenv-0.20.0-py3-none-any.whl (17 kB)\n","Collecting spacy>=3.2.0\n","  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[K     |████████████████████████████████| 6.0 MB 48.2 MB/s \n","\u001b[?25hRequirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (8.0.17)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (0.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (21.3)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (0.4.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (0.6.1)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (1.0.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (2.0.7)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (2.11.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (3.3.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (2.4.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (1.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (3.0.6)\n","Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (7.1.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (1.8.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (0.9.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (57.4.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (3.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->-r requirements.txt (line 1)) (2.0.6)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1->-r requirements.txt (line 3)) (5.3.0)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1->-r requirements.txt (line 3)) (5.3.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter>=1->-r requirements.txt (line 3)) (7.7.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1->-r requirements.txt (line 3)) (5.6.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1->-r requirements.txt (line 3)) (5.2.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter>=1->-r requirements.txt (line 3)) (6.13.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.4->-r requirements.txt (line 4)) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.4->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.3->-r requirements.txt (line 14)) (21.4.0)\n","Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.3->-r requirements.txt (line 14)) (1.11.0)\n","Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.3->-r requirements.txt (line 14)) (4.11.4)\n","Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.3->-r requirements.txt (line 14)) (2.0.1)\n","Collecting pluggy<2.0,>=0.12\n","  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.7/dist-packages (from pytest>=6.2.3->-r requirements.txt (line 14)) (1.1.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->-r requirements.txt (line 17)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->-r requirements.txt (line 17)) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->-r requirements.txt (line 17)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.25.1->-r requirements.txt (line 17)) (2022.5.18.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.0->-r requirements.txt (line 1)) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.2.0->-r requirements.txt (line 1)) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.0->-r requirements.txt (line 1)) (5.2.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.4->-r requirements.txt (line 4)) (1.15.0)\n","Collecting pycountry\n","  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 44.1 MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Collecting iso3166\n","  Downloading iso3166-2.0.2-py3-none-any.whl (8.5 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from schwifty->-r requirements.txt (line 7)) (5.7.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn->-r requirements.txt (line 9)) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn->-r requirements.txt (line 9)) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn->-r requirements.txt (line 9)) (1.1.0)\n","Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from presidio_analyzer->-r requirements.txt (line 15)) (3.3.0)\n","Requirement already satisfied: phonenumbers>=8.12 in /usr/local/lib/python3.7/dist-packages (from presidio_analyzer->-r requirements.txt (line 15)) (8.12.49)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from presidio_analyzer->-r requirements.txt (line 15)) (2019.12.20)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from presidio_analyzer->-r requirements.txt (line 15)) (6.0)\n","Requirement already satisfied: pycryptodome>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from presidio_anonymizer->-r requirements.txt (line 16)) (3.14.1)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (1.5.5)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.1.3)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (7.34.0)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (6.1)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (5.1.1)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (7.3.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (5.4.8)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter>=1->-r requirements.txt (line 3)) (1.0.0)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (3.0.29)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.18.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (2.6.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (4.4.2)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.7.5)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.8.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.4)\n","Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (4.10.0)\n","Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (23.0.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->jupyter>=1->-r requirements.txt (line 3)) (0.2.5)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1->-r requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1->-r requirements.txt (line 3)) (5.4.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1->-r requirements.txt (line 3)) (1.1.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter>=1->-r requirements.txt (line 3)) (3.6.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter>=1->-r requirements.txt (line 3)) (4.3.3)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter>=1->-r requirements.txt (line 3)) (2.15.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->jupyter>=1->-r requirements.txt (line 3)) (0.18.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1->-r requirements.txt (line 3)) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1->-r requirements.txt (line 3)) (1.8.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.0->-r requirements.txt (line 1)) (2.0.1)\n","Collecting jupyter-console\n","  Downloading jupyter_console-6.4.3-py3-none-any.whl (22 kB)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1->-r requirements.txt (line 3)) (0.8.4)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1->-r requirements.txt (line 3)) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1->-r requirements.txt (line 3)) (5.0.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1->-r requirements.txt (line 3)) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1->-r requirements.txt (line 3)) (0.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1->-r requirements.txt (line 3)) (0.5.1)\n","Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1->-r requirements.txt (line 3)) (2.1.0)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->presidio_analyzer->-r requirements.txt (line 15)) (3.7.0)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract->presidio_analyzer->-r requirements.txt (line 15)) (1.5.1)\n","Building wheels for collected packages: en-core-web-sm, pycountry\n","  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-sm: filename=en_core_web_sm-3.2.0-py3-none-any.whl size=13900222 sha256=90e04c0895a0216ae52b1035d04d54bc58940400879a8e71c80dc4a9e3d14f2a\n","  Stored in directory: /root/.cache/pip/wheels/74/78/1e/95aaf37382a98607520e3000839efb963061093062dadc0e7d\n","  Building wheel for pycountry (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681845 sha256=72ff0c228dfe6cad5b75c9756a45eda043f92047d609fb8da75b2f1c72739815\n","  Stored in directory: /root/.cache/pip/wheels/0e/06/e8/7ee176e95ea9a8a8c3b3afcb1869f20adbd42413d4611c6eb4\n","Successfully built en-core-web-sm pycountry\n","Installing collected packages: typing-extensions, requests, spacy, pycountry, pluggy, jupyter-console, iso3166, xmltodict, schwifty, python-dotenv, pytest, haikunator, faker, en-core-web-sm\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.1.1\n","    Uninstalling typing-extensions-4.1.1:\n","      Successfully uninstalled typing-extensions-4.1.1\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 3.3.1\n","    Uninstalling spacy-3.3.1:\n","      Successfully uninstalled spacy-3.3.1\n","  Attempting uninstall: pluggy\n","    Found existing installation: pluggy 0.7.1\n","    Uninstalling pluggy-0.7.1:\n","      Successfully uninstalled pluggy-0.7.1\n","  Attempting uninstall: jupyter-console\n","    Found existing installation: jupyter-console 5.2.0\n","    Uninstalling jupyter-console-5.2.0:\n","      Successfully uninstalled jupyter-console-5.2.0\n","  Attempting uninstall: pytest\n","    Found existing installation: pytest 3.6.4\n","    Uninstalling pytest-3.6.4:\n","      Successfully uninstalled pytest-3.6.4\n","  Attempting uninstall: en-core-web-sm\n","    Found existing installation: en-core-web-sm 2.2.5\n","    Uninstalling en-core-web-sm-2.2.5:\n","      Successfully uninstalled en-core-web-sm-2.2.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.1+cu111 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","cs-gpu-bert-cased 0.0.0 requires spacy<3.4.0,>=3.3.1, but you have spacy 3.2.4 which is incompatible.\u001b[0m\n","Successfully installed en-core-web-sm-3.2.0 faker-13.13.0 haikunator-2.1.0 iso3166-2.0.2 jupyter-console-6.4.3 pluggy-1.0.0 pycountry-22.3.5 pytest-7.1.2 python-dotenv-0.20.0 requests-2.28.0 schwifty-2022.6.0 spacy-3.2.4 typing-extensions-3.10.0.2 xmltodict-0.13.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["_pytest","pluggy","pytest","requests","spacy","typing_extensions"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["running install\n","running bdist_egg\n","running egg_info\n","creating presidio_evaluator.egg-info\n","writing presidio_evaluator.egg-info/PKG-INFO\n","writing dependency_links to presidio_evaluator.egg-info/dependency_links.txt\n","writing requirements to presidio_evaluator.egg-info/requires.txt\n","writing top-level names to presidio_evaluator.egg-info/top_level.txt\n","writing manifest file 'presidio_evaluator.egg-info/SOURCES.txt'\n","adding license file 'LICENSE'\n","adding license file 'NOTICE'\n","writing manifest file 'presidio_evaluator.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/presidio_evaluator\n","copying presidio_evaluator/validation.py -> build/lib/presidio_evaluator\n","copying presidio_evaluator/data_objects.py -> build/lib/presidio_evaluator\n","copying presidio_evaluator/__init__.py -> build/lib/presidio_evaluator\n","copying presidio_evaluator/span_to_tag.py -> build/lib/presidio_evaluator\n","creating build/lib/presidio_evaluator/experiment_tracking\n","copying presidio_evaluator/experiment_tracking/experiment_tracker.py -> build/lib/presidio_evaluator/experiment_tracking\n","copying presidio_evaluator/experiment_tracking/__init__.py -> build/lib/presidio_evaluator/experiment_tracking\n","creating build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/presidio_recognizer_wrapper.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/spacy_model.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/stanza_model.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/flair_train.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/__init__.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/base_model.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/flair_model.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/crf_model.py -> build/lib/presidio_evaluator/models\n","copying presidio_evaluator/models/presidio_analyzer_wrapper.py -> build/lib/presidio_evaluator/models\n","creating build/lib/presidio_evaluator/data_generator\n","copying presidio_evaluator/data_generator/presidio_data_generator.py -> build/lib/presidio_evaluator/data_generator\n","copying presidio_evaluator/data_generator/__init__.py -> build/lib/presidio_evaluator/data_generator\n","copying presidio_evaluator/data_generator/presidio_pseudonymize.py -> build/lib/presidio_evaluator/data_generator\n","creating build/lib/presidio_evaluator/evaluation\n","copying presidio_evaluator/evaluation/__init__.py -> build/lib/presidio_evaluator/evaluation\n","copying presidio_evaluator/evaluation/evaluator.py -> build/lib/presidio_evaluator/evaluation\n","copying presidio_evaluator/evaluation/scorers.py -> build/lib/presidio_evaluator/evaluation\n","copying presidio_evaluator/evaluation/evaluation_result.py -> build/lib/presidio_evaluator/evaluation\n","copying presidio_evaluator/evaluation/model_error.py -> build/lib/presidio_evaluator/evaluation\n","creating build/lib/presidio_evaluator/dataset_formatters\n","copying presidio_evaluator/dataset_formatters/dataset_formatter.py -> build/lib/presidio_evaluator/dataset_formatters\n","copying presidio_evaluator/dataset_formatters/__init__.py -> build/lib/presidio_evaluator/dataset_formatters\n","copying presidio_evaluator/dataset_formatters/conll_formatter.py -> build/lib/presidio_evaluator/dataset_formatters\n","copying presidio_evaluator/dataset_formatters/i2b2_formatter.py -> build/lib/presidio_evaluator/dataset_formatters\n","creating build/lib/presidio_evaluator/data_generator/faker_extensions\n","copying presidio_evaluator/data_generator/faker_extensions/providers.py -> build/lib/presidio_evaluator/data_generator/faker_extensions\n","copying presidio_evaluator/data_generator/faker_extensions/records_faker.py -> build/lib/presidio_evaluator/data_generator/faker_extensions\n","copying presidio_evaluator/data_generator/faker_extensions/span_generator.py -> build/lib/presidio_evaluator/data_generator/faker_extensions\n","copying presidio_evaluator/data_generator/faker_extensions/data_objects.py -> build/lib/presidio_evaluator/data_generator/faker_extensions\n","copying presidio_evaluator/data_generator/faker_extensions/__init__.py -> build/lib/presidio_evaluator/data_generator/faker_extensions\n","copying presidio_evaluator/data_generator/faker_extensions/record_generator.py -> build/lib/presidio_evaluator/data_generator/faker_extensions\n","creating build/lib/tests\n","creating build/lib/tests/mocks\n","copying tests/mocks/__init__.py -> build/lib/tests/mocks\n","copying tests/mocks/model_mock.py -> build/lib/tests/mocks\n","copying presidio_evaluator/data_generator/README.md -> build/lib/presidio_evaluator/data_generator\n","creating build/lib/presidio_evaluator/data_generator/raw_data\n","copying presidio_evaluator/data_generator/raw_data/FakeNameGenerator.com_3000.csv -> build/lib/presidio_evaluator/data_generator/raw_data\n","copying presidio_evaluator/data_generator/raw_data/nationalities.csv -> build/lib/presidio_evaluator/data_generator/raw_data\n","copying presidio_evaluator/data_generator/raw_data/organizations.csv -> build/lib/presidio_evaluator/data_generator/raw_data\n","copying presidio_evaluator/data_generator/raw_data/templates.txt -> build/lib/presidio_evaluator/data_generator/raw_data\n","copying presidio_evaluator/data_generator/raw_data/us_driver_licenses.csv -> build/lib/presidio_evaluator/data_generator/raw_data\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator/experiment_tracking\n","copying build/lib/presidio_evaluator/experiment_tracking/experiment_tracker.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/experiment_tracking\n","copying build/lib/presidio_evaluator/experiment_tracking/__init__.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/experiment_tracking\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/presidio_recognizer_wrapper.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/spacy_model.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/stanza_model.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/flair_train.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/__init__.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/base_model.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/flair_model.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/crf_model.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/models/presidio_analyzer_wrapper.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/models\n","copying build/lib/presidio_evaluator/validation.py -> build/bdist.linux-x86_64/egg/presidio_evaluator\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator\n","copying build/lib/presidio_evaluator/data_generator/README.md -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions\n","copying build/lib/presidio_evaluator/data_generator/faker_extensions/providers.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions\n","copying build/lib/presidio_evaluator/data_generator/faker_extensions/records_faker.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions\n","copying build/lib/presidio_evaluator/data_generator/faker_extensions/span_generator.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions\n","copying build/lib/presidio_evaluator/data_generator/faker_extensions/data_objects.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions\n","copying build/lib/presidio_evaluator/data_generator/faker_extensions/__init__.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions\n","copying build/lib/presidio_evaluator/data_generator/faker_extensions/record_generator.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/raw_data\n","copying build/lib/presidio_evaluator/data_generator/raw_data/nationalities.csv -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/raw_data\n","copying build/lib/presidio_evaluator/data_generator/raw_data/FakeNameGenerator.com_3000.csv -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/raw_data\n","copying build/lib/presidio_evaluator/data_generator/raw_data/organizations.csv -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/raw_data\n","copying build/lib/presidio_evaluator/data_generator/raw_data/templates.txt -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/raw_data\n","copying build/lib/presidio_evaluator/data_generator/raw_data/us_driver_licenses.csv -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/raw_data\n","copying build/lib/presidio_evaluator/data_generator/presidio_data_generator.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator\n","copying build/lib/presidio_evaluator/data_generator/__init__.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator\n","copying build/lib/presidio_evaluator/data_generator/presidio_pseudonymize.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator\n","copying build/lib/presidio_evaluator/data_objects.py -> build/bdist.linux-x86_64/egg/presidio_evaluator\n","copying build/lib/presidio_evaluator/__init__.py -> build/bdist.linux-x86_64/egg/presidio_evaluator\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation\n","copying build/lib/presidio_evaluator/evaluation/__init__.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation\n","copying build/lib/presidio_evaluator/evaluation/evaluator.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation\n","copying build/lib/presidio_evaluator/evaluation/scorers.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation\n","copying build/lib/presidio_evaluator/evaluation/evaluation_result.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation\n","copying build/lib/presidio_evaluator/evaluation/model_error.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation\n","creating build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters\n","copying build/lib/presidio_evaluator/dataset_formatters/dataset_formatter.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters\n","copying build/lib/presidio_evaluator/dataset_formatters/__init__.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters\n","copying build/lib/presidio_evaluator/dataset_formatters/conll_formatter.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters\n","copying build/lib/presidio_evaluator/dataset_formatters/i2b2_formatter.py -> build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters\n","copying build/lib/presidio_evaluator/span_to_tag.py -> build/bdist.linux-x86_64/egg/presidio_evaluator\n","creating build/bdist.linux-x86_64/egg/tests\n","creating build/bdist.linux-x86_64/egg/tests/mocks\n","copying build/lib/tests/mocks/__init__.py -> build/bdist.linux-x86_64/egg/tests/mocks\n","copying build/lib/tests/mocks/model_mock.py -> build/bdist.linux-x86_64/egg/tests/mocks\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/experiment_tracking/experiment_tracker.py to experiment_tracker.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/experiment_tracking/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/presidio_recognizer_wrapper.py to presidio_recognizer_wrapper.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/spacy_model.py to spacy_model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/stanza_model.py to stanza_model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/flair_train.py to flair_train.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/base_model.py to base_model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/flair_model.py to flair_model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/crf_model.py to crf_model.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/models/presidio_analyzer_wrapper.py to presidio_analyzer_wrapper.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/validation.py to validation.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions/providers.py to providers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions/records_faker.py to records_faker.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions/span_generator.py to span_generator.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions/data_objects.py to data_objects.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/faker_extensions/record_generator.py to record_generator.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/presidio_data_generator.py to presidio_data_generator.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_generator/presidio_pseudonymize.py to presidio_pseudonymize.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/data_objects.py to data_objects.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation/evaluator.py to evaluator.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation/scorers.py to scorers.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation/evaluation_result.py to evaluation_result.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/evaluation/model_error.py to model_error.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters/dataset_formatter.py to dataset_formatter.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters/conll_formatter.py to conll_formatter.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/dataset_formatters/i2b2_formatter.py to i2b2_formatter.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/presidio_evaluator/span_to_tag.py to span_to_tag.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/tests/mocks/__init__.py to __init__.cpython-37.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/tests/mocks/model_mock.py to model_mock.cpython-37.pyc\n","installing package data to build/bdist.linux-x86_64/egg\n","running install_data\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying presidio_evaluator.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying presidio_evaluator.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying presidio_evaluator.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying presidio_evaluator.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying presidio_evaluator.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","presidio_evaluator.data_generator.__pycache__.presidio_data_generator.cpython-37: module references __file__\n","presidio_evaluator.data_generator.faker_extensions.__pycache__.providers.cpython-37: module references __file__\n","creating dist\n","creating 'dist/presidio_evaluator-0.1.0-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing presidio_evaluator-0.1.0-py3.7.egg\n","creating /usr/local/lib/python3.7/dist-packages/presidio_evaluator-0.1.0-py3.7.egg\n","Extracting presidio_evaluator-0.1.0-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n","Adding presidio-evaluator 0.1.0 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/presidio_evaluator-0.1.0-py3.7.egg\n","Processing dependencies for presidio-evaluator==0.1.0\n","Searching for sklearn_crfsuite\n","Reading https://pypi.org/simple/sklearn_crfsuite/\n","Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl#sha256=6e9a42bc3de96941d5f7262335130955b8c380b1356147622368f385075705d9\n","Best match: sklearn-crfsuite 0.3.6\n","Processing sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n","Installing sklearn_crfsuite-0.3.6-py2.py3-none-any.whl to /usr/local/lib/python3.7/dist-packages\n","Adding sklearn-crfsuite 0.3.6 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/sklearn_crfsuite-0.3.6-py3.7.egg\n","Searching for python-crfsuite>=0.8.3\n","Reading https://pypi.org/simple/python-crfsuite/\n","Downloading https://files.pythonhosted.org/packages/16/c0/e61ec91560d34518a4986a29898f15248a226e7bf201ade882f5fda8f7c1/python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=c79688357ef67efbac619048d69abf61eba4c316423ef20d4d2174afcd7e705d\n","Best match: python-crfsuite 0.9.8\n","Processing python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","Installing python_crfsuite-0.9.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.7/dist-packages\n","Adding python-crfsuite 0.9.8 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.7/dist-packages/python_crfsuite-0.9.8-py3.7-linux-x86_64.egg\n","Searching for python-dotenv==0.20.0\n","Best match: python-dotenv 0.20.0\n","Adding python-dotenv 0.20.0 to easy-install.pth file\n","Installing dotenv script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for Faker==13.13.0\n","Best match: Faker 13.13.0\n","Adding Faker 13.13.0 to easy-install.pth file\n","Installing faker script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for schwifty==2022.6.0\n","Best match: schwifty 2022.6.0\n","Adding schwifty 2022.6.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for haikunator==2.1.0\n","Best match: haikunator 2.1.0\n","Adding haikunator 2.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pytest==7.1.2\n","Best match: pytest 7.1.2\n","Adding pytest 7.1.2 to easy-install.pth file\n","Installing py.test script to /usr/local/bin\n","Installing pytest script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for jupyter==1.0.0\n","Best match: jupyter 1.0.0\n","Adding jupyter 1.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for tqdm==4.64.0\n","Best match: tqdm 4.64.0\n","Adding tqdm 4.64.0 to easy-install.pth file\n","Installing tqdm script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pandas==1.3.5\n","Best match: pandas 1.3.5\n","Adding pandas 1.3.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for numpy==1.21.6\n","Best match: numpy 1.21.6\n","Adding numpy 1.21.6 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.7 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for requests==2.28.0\n","Best match: requests 2.28.0\n","Adding requests 2.28.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for spacy==3.2.4\n","Best match: spacy 3.2.4\n","Adding spacy 3.2.4 to easy-install.pth file\n","Installing spacy script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for tabulate==0.8.9\n","Best match: tabulate 0.8.9\n","Adding tabulate 0.8.9 to easy-install.pth file\n","Installing tabulate script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for six==1.15.0\n","Best match: six 1.15.0\n","Adding six 1.15.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for python-dateutil==2.8.2\n","Best match: python-dateutil 2.8.2\n","Adding python-dateutil 2.8.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for typing-extensions==3.10.0.2\n","Best match: typing-extensions 3.10.0.2\n","Adding typing-extensions 3.10.0.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for importlib-resources==5.7.1\n","Best match: importlib-resources 5.7.1\n","Adding importlib-resources 5.7.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pycountry==22.3.5\n","Best match: pycountry 22.3.5\n","Adding pycountry 22.3.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for iso3166==2.0.2\n","Best match: iso3166 2.0.2\n","Adding iso3166 2.0.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for importlib-metadata==4.11.4\n","Best match: importlib-metadata 4.11.4\n","Adding importlib-metadata 4.11.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for packaging==21.3\n","Best match: packaging 21.3\n","Adding packaging 21.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for tomli==2.0.1\n","Best match: tomli 2.0.1\n","Adding tomli 2.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for attrs==21.4.0\n","Best match: attrs 21.4.0\n","Adding attrs 21.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pluggy==1.0.0\n","Best match: pluggy 1.0.0\n","Adding pluggy 1.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for py==1.11.0\n","Best match: py 1.11.0\n","Adding py 1.11.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for iniconfig==1.1.1\n","Best match: iniconfig 1.1.1\n","Adding iniconfig 1.1.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for qtconsole==5.3.0\n","Best match: qtconsole 5.3.0\n","Adding qtconsole 5.3.0 to easy-install.pth file\n","Installing jupyter-qtconsole script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for ipykernel==6.13.1\n","Best match: ipykernel 6.13.1\n","Adding ipykernel 6.13.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for ipywidgets==7.7.0\n","Best match: ipywidgets 7.7.0\n","Adding ipywidgets 7.7.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for jupyter-console==6.4.3\n","Best match: jupyter-console 6.4.3\n","Adding jupyter-console 6.4.3 to easy-install.pth file\n","Installing jupyter-console script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for notebook==5.3.1\n","Best match: notebook 5.3.1\n","Adding notebook 5.3.1 to easy-install.pth file\n","Installing jupyter-bundlerextension script to /usr/local/bin\n","Installing jupyter-nbextension script to /usr/local/bin\n","Installing jupyter-notebook script to /usr/local/bin\n","Installing jupyter-serverextension script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for nbconvert==5.6.1\n","Best match: nbconvert 5.6.1\n","Adding nbconvert 5.6.1 to easy-install.pth file\n","Installing jupyter-nbconvert script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pytz==2022.1\n","Best match: pytz 2022.1\n","Adding pytz 2022.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for certifi==2022.5.18.1\n","Best match: certifi 2022.5.18.1\n","Adding certifi 2022.5.18.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for idna==2.10\n","Best match: idna 2.10\n","Adding idna 2.10 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for urllib3==1.24.3\n","Best match: urllib3 1.24.3\n","Adding urllib3 1.24.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for charset-normalizer==2.0.12\n","Best match: charset-normalizer 2.0.12\n","Adding charset-normalizer 2.0.12 to easy-install.pth file\n","Installing normalizer script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for preshed==3.0.6\n","Best match: preshed 3.0.6\n","Adding preshed 3.0.6 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for blis==0.4.1\n","Best match: blis 0.4.1\n","Adding blis 0.4.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for cymem==2.0.6\n","Best match: cymem 2.0.6\n","Adding cymem 2.0.6 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for murmurhash==1.0.7\n","Best match: murmurhash 1.0.7\n","Adding murmurhash 1.0.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for spacy-loggers==1.0.2\n","Best match: spacy-loggers 1.0.2\n","Adding spacy-loggers 1.0.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pathy==0.6.1\n","Best match: pathy 0.6.1\n","Adding pathy 0.6.1 to easy-install.pth file\n","Installing pathy script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for wasabi==0.9.1\n","Best match: wasabi 0.9.1\n","Adding wasabi 0.9.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for srsly==2.4.3\n","Best match: srsly 2.4.3\n","Adding srsly 2.4.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for typer==0.4.1\n","Best match: typer 0.4.1\n","Adding typer 0.4.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for setuptools==57.4.0\n","Best match: setuptools 57.4.0\n","Adding setuptools 57.4.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for click==7.1.2\n","Best match: click 7.1.2\n","Adding click 7.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for thinc==8.0.17\n","Best match: thinc 8.0.17\n","Adding thinc 8.0.17 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for catalogue==2.0.7\n","Best match: catalogue 2.0.7\n","Adding catalogue 2.0.7 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pydantic==1.8.2\n","Best match: pydantic 1.8.2\n","Adding pydantic 1.8.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for spacy-legacy==3.0.9\n","Best match: spacy-legacy 3.0.9\n","Adding spacy-legacy 3.0.9 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for Jinja2==2.11.3\n","Best match: Jinja2 2.11.3\n","Adding Jinja2 2.11.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for langcodes==3.3.0\n","Best match: langcodes 3.3.0\n","Adding langcodes 3.3.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for zipp==3.8.0\n","Best match: zipp 3.8.0\n","Adding zipp 3.8.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pyparsing==3.0.9\n","Best match: pyparsing 3.0.9\n","Adding pyparsing 3.0.9 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for ipython-genutils==0.2.0\n","Best match: ipython-genutils 0.2.0\n","Adding ipython-genutils 0.2.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for jupyter-core==4.10.0\n","Best match: jupyter-core 4.10.0\n","Adding jupyter-core 4.10.0 to easy-install.pth file\n","Installing jupyter script to /usr/local/bin\n","Installing jupyter-migrate script to /usr/local/bin\n","Installing jupyter-troubleshoot script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for traitlets==5.1.1\n","Best match: traitlets 5.1.1\n","Adding traitlets 5.1.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for Pygments==2.6.1\n","Best match: Pygments 2.6.1\n","Adding Pygments 2.6.1 to easy-install.pth file\n","Installing pygmentize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for jupyter-client==7.3.4\n","Best match: jupyter-client 7.3.4\n","Adding jupyter-client 7.3.4 to easy-install.pth file\n","Installing jupyter-kernel script to /usr/local/bin\n","Installing jupyter-kernelspec script to /usr/local/bin\n","Installing jupyter-run script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for QtPy==2.1.0\n","Best match: QtPy 2.1.0\n","Adding QtPy 2.1.0 to easy-install.pth file\n","Installing qtpy script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pyzmq==23.0.0\n","Best match: pyzmq 23.0.0\n","Adding pyzmq 23.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for psutil==5.4.8\n","Best match: psutil 5.4.8\n","Adding psutil 5.4.8 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for debugpy==1.0.0\n","Best match: debugpy 1.0.0\n","Adding debugpy 1.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for ipython==7.34.0\n","Best match: ipython 7.34.0\n","Adding ipython 7.34.0 to easy-install.pth file\n","Installing iptest script to /usr/local/bin\n","Installing iptest3 script to /usr/local/bin\n","Installing ipython script to /usr/local/bin\n","Installing ipython3 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for nest-asyncio==1.5.5\n","Best match: nest-asyncio 1.5.5\n","Adding nest-asyncio 1.5.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for matplotlib-inline==0.1.3\n","Best match: matplotlib-inline 0.1.3\n","Adding matplotlib-inline 0.1.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for tornado==6.1\n","Best match: tornado 6.1\n","Adding tornado 6.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for widgetsnbextension==3.6.0\n","Best match: widgetsnbextension 3.6.0\n","Adding widgetsnbextension 3.6.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for jupyterlab-widgets==1.1.0\n","Best match: jupyterlab-widgets 1.1.0\n","Adding jupyterlab-widgets 1.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for nbformat==5.4.0\n","Best match: nbformat 5.4.0\n","Adding nbformat 5.4.0 to easy-install.pth file\n","Installing jupyter-trust script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for prompt-toolkit==3.0.29\n","Best match: prompt-toolkit 3.0.29\n","Adding prompt-toolkit 3.0.29 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for terminado==0.13.3\n","Best match: terminado 0.13.3\n","Adding terminado 0.13.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for Send2Trash==1.8.0\n","Best match: Send2Trash 1.8.0\n","Adding Send2Trash 1.8.0 to easy-install.pth file\n","Installing send2trash script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for testpath==0.6.0\n","Best match: testpath 0.6.0\n","Adding testpath 0.6.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for mistune==0.8.4\n","Best match: mistune 0.8.4\n","Adding mistune 0.8.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for bleach==5.0.0\n","Best match: bleach 5.0.0\n","Adding bleach 5.0.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for defusedxml==0.7.1\n","Best match: defusedxml 0.7.1\n","Adding defusedxml 0.7.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for entrypoints==0.4\n","Best match: entrypoints 0.4\n","Adding entrypoints 0.4 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pandocfilters==1.5.0\n","Best match: pandocfilters 1.5.0\n","Adding pandocfilters 1.5.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for smart-open==5.2.1\n","Best match: smart-open 5.2.1\n","Adding smart-open 5.2.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for MarkupSafe==2.0.1\n","Best match: MarkupSafe 2.0.1\n","Adding MarkupSafe 2.0.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for jedi==0.18.1\n","Best match: jedi 0.18.1\n","Adding jedi 0.18.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for decorator==4.4.2\n","Best match: decorator 4.4.2\n","Adding decorator 4.4.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pexpect==4.8.0\n","Best match: pexpect 4.8.0\n","Adding pexpect 4.8.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for backcall==0.2.0\n","Best match: backcall 0.2.0\n","Adding backcall 0.2.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pickleshare==0.7.5\n","Best match: pickleshare 0.7.5\n","Adding pickleshare 0.7.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for jsonschema==4.3.3\n","Best match: jsonschema 4.3.3\n","Adding jsonschema 4.3.3 to easy-install.pth file\n","Installing jsonschema script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for fastjsonschema==2.15.3\n","Best match: fastjsonschema 2.15.3\n","Adding fastjsonschema 2.15.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for wcwidth==0.2.5\n","Best match: wcwidth 0.2.5\n","Adding wcwidth 0.2.5 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for ptyprocess==0.7.0\n","Best match: ptyprocess 0.7.0\n","Adding ptyprocess 0.7.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for webencodings==0.5.1\n","Best match: webencodings 0.5.1\n","Adding webencodings 0.5.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for parso==0.8.3\n","Best match: parso 0.8.3\n","Adding parso 0.8.3 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Searching for pyrsistent==0.18.1\n","Best match: pyrsistent 0.18.1\n","Adding pyrsistent 0.18.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.7/dist-packages\n","Finished processing dependencies for presidio-evaluator==0.1.0\n"]}],"source":["!pip install -r requirements.txt\n","!python setup.py install"]},{"cell_type":"markdown","metadata":{"id":"GfQpSK6wTp9W"},"source":["Import required modules"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1654880634636,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"-jUVaVocSg2_","outputId":"2dc0da05-6638-448e-837f-e8bfd03ead41"},"outputs":[{"name":"stdout","output_type":"stream","text":["stanza and spacy_stanza are not installed\n","Flair is not installed by default\n","Flair is not installed\n"]}],"source":["from copy import deepcopy\n","from pprint import pprint\n","import pandas as pd\n","\n","from presidio_evaluator import InputSample\n","from presidio_evaluator.evaluation import Evaluator, ModelError\n","from presidio_evaluator.models import PresidioAnalyzerWrapper"]},{"cell_type":"markdown","metadata":{"id":"6Nk_ZdWhUNM5"},"source":["Evaluation dataset **contract_eval** contains a real world example of a contract, which needs to be anonymized before uploading to \"Veřejný registr smluv\".\n","\n","It was annotated by the author, using the Label Studio annotation tool. This tool has an option to export annotated dataset in a CONLL2003ish format, which can be then after applying a simple fix converted to a spaCy V3 binary format."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8854,"status":"ok","timestamp":1654876879694,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"8YAe0C1Tb5jn","outputId":"32a6a9ad-9854-4321-92bd-0ce63f31932f"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘/content/drive/MyDrive/PIIAnonymizer/datasets/eval’: File exists\n","\u001b[38;5;3m⚠ Document delimiters found, automatic document segmentation with `-n`\n","disabled.\u001b[0m\n","\u001b[38;5;2m✔ Generated output file (1 documents):\n","/content/drive/MyDrive/PIIAnonymizer/datasets/eval/contract_eval.spacy\u001b[0m\n"]}],"source":["!mkdir '/content/drive/MyDrive/PIIAnonymizer/datasets/eval'\n","!python -m spacy convert -n 10 '/content/DP/eval/contract_eval.conll' '/content/drive/MyDrive/PIIAnonymizer/datasets/eval'"]},{"cell_type":"markdown","metadata":{"id":"1GwnGQGGWYsh"},"source":["Load contract_eval dataset as a list of spaCy Docs"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":905,"status":"ok","timestamp":1654880635537,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"NFd-jPqbdIZJ"},"outputs":[],"source":["docbin = dataset_docs_from_path('/content/drive/MyDrive/PIIAnonymizer/datasets/eval/contract_eval.spacy')"]},{"cell_type":"markdown","metadata":{"id":"0GbXHWAvWh7g"},"source":["And convert these docs to a presidio-research evaluation data container (list of InputSamples)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1654880635538,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"G3kIaczIdfWG"},"outputs":[],"source":["input_samples = []\n","for doc in docbin:\n","  input_samples.append(InputSample.from_spacy_doc(doc=doc))"]},{"cell_type":"markdown","metadata":{"id":"gNTPx6nmXDKe"},"source":["Then, since PresidioAnalyzerWrapper, available at https://github.com/microsoft/presidio-research/blob/master/presidio_evaluator/models/presidio_analyzer_wrapper.py contains a bug, which prevents from loading custom presidio recognizers in other language than \"en\", I copied the PresidioAnalyzerWrapper implementation and fix the bug myself."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1654880635538,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"Wkr3QBbebG7F"},"outputs":[],"source":["#NOTE: this code is available at https://github.com/microsoft/presidio-research/blob/master/presidio_evaluator/models/presidio_analyzer_wrapper.py\n","\n","from typing import List, Optional, Dict\n","\n","from presidio_analyzer import AnalyzerEngine\n","\n","from presidio_evaluator import InputSample, span_to_tag\n","from presidio_evaluator.models import BaseModel\n","\n","\n","class PresidioAnalyzerWrapper(BaseModel):\n","    def __init__(\n","        self,\n","        analyzer_engine: Optional[AnalyzerEngine] = None,\n","        entities_to_keep: List[str] = None,\n","        verbose: bool = False,\n","        labeling_scheme: str = \"BIO\",\n","        score_threshold: float = 0.4,\n","        language: str = \"en\",\n","        entity_mapping: Optional[Dict[str, str]] = None,\n","    ):\n","        \"\"\"\n","        Evaluation wrapper for the Presidio Analyzer\n","        :param analyzer_engine: object of type AnalyzerEngine (from presidio-analyzer)\n","        \"\"\"\n","        super().__init__(\n","            entities_to_keep=entities_to_keep,\n","            verbose=verbose,\n","            labeling_scheme=labeling_scheme,\n","            entity_mapping=entity_mapping,\n","        )\n","        self.score_threshold = score_threshold\n","        self.language = language\n","\n","        if not analyzer_engine:\n","            analyzer_engine = AnalyzerEngine()\n","            self._update_recognizers_based_on_entities_to_keep(analyzer_engine)\n","        self.analyzer_engine = analyzer_engine\n","\n","    def predict(self, sample: InputSample) -> List[str]:\n","\n","        results = self.analyzer_engine.analyze(\n","            text=sample.full_text,\n","            entities=self.entities,\n","            language=\"cs\",\n","            score_threshold=self.score_threshold,\n","        )\n","        starts = []\n","        ends = []\n","        scores = []\n","        tags = []\n","        #\n","        for res in results:\n","            starts.append(res.start)\n","            ends.append(res.end)\n","            tags.append(res.entity_type)\n","            scores.append(res.score)\n","\n","        response_tags = span_to_tag(\n","            scheme=\"IO\",\n","            text=sample.full_text,\n","            starts=starts,\n","            ends=ends,\n","            tokens=sample.tokens,\n","            scores=scores,\n","            tags=tags,\n","        )\n","        return response_tags\n","\n","\n","    def _update_recognizers_based_on_entities_to_keep(\n","        self, analyzer_engine: AnalyzerEngine\n","    ):\n","        \"\"\"Check if there are any entities not supported by this presidio instance.\n","        Add ORGANIZATION as it is removed by default\n","        \"\"\"\n","        supported_entities = analyzer_engine.get_supported_entities(\n","            language=self.language\n","        )\n","        print(\"Entities supported by this Presidio Analyzer instance:\")\n","        print(\", \".join(supported_entities))\n","\n","        if not self.entities:\n","            self.entities = supported_entities\n","\n","        for entity in self.entities:\n","            if entity not in supported_entities:\n","                print(\n","                    f\"Entity {entity} is not supported by this instance of Presidio Analyzer Engine\"\n","                )\n","\n","        if \"ORGANIZATION\" in self.entities and \"ORGANIZATION\" not in supported_entities:\n","            recognizers = analyzer_engine.get_recognizers()\n","            spacy_recognizer = [\n","                rec\n","                for rec in recognizers\n","                if rec.name == \"SpacyRecognizer\" or rec.name == \"StanzaRecognizer\"\n","            ]\n","            if len(spacy_recognizer):\n","                spacy_recognizer = spacy_recognizer[0]\n","                spacy_recognizer.supported_entities.append(\"ORGANIZATION\")\n","                self.entities.append(\"ORGANIZATION\")\n","                print(\"Added ORGANIZATION as a supported entity from spaCy/Stanza\")"]},{"cell_type":"markdown","metadata":{"id":"j0tw_rBbY9eJ"},"source":["The whole PIIAnonymizer tool is then evaluated on a contract_eval dataset.\n","\n","presidio-research package uses the PresidioAnalyzerWrapper to load the analyze engine and Evaluator object to run inference on a eval dataset and to calculate a final metrics - Presision, Recall and F1 score."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32156,"status":"ok","timestamp":1654880667691,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"Hx9a4czAEdRd","outputId":"5feb4017-d629-48f4-e28f-e0fa71823767"},"outputs":[{"name":"stderr","output_type":"stream","text":["Evaluating <class '__main__.PresidioAnalyzerWrapper'>: 100%|██████████| 1/1 [00:32<00:00, 32.07s/it]"]},{"name":"stdout","output_type":"stream","text":["              Entity           Precision              Recall   Number of samples\n","         INSTITUTION                nan%               0.00%                  22\n","            LOCATION              94.44%              87.18%                  39\n","              DOMAIN                nan%               0.00%                   1\n","           IBAN_CODE             100.00%             100.00%                   1\n","           DATE_TIME              46.67%              77.78%                   9\n","           PHONE_NUM             100.00%             100.00%                   5\n","       EMAIL_ADDRESS             100.00%             100.00%                   2\n","              PERSON              75.00%             100.00%                   9\n","               OTHER              46.43%              54.17%                  24\n","         NUMBER_EXPR              92.31%              89.36%                  94\n","                 PII              85.64%              81.07%                 206\n","PII F measure: 81.67%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["presidio_entities_map = {\n","        \"PERSON\": \"PERSON\",\n","        \"LOCATION\": \"LOCATION\",\n","        \"EMAIL_ADDRESS\": \"EMAIL_ADDRESS\",\n","        \"CREDIT_CARD\": \"CREDIT_CARD\",\n","        \"PHONE_NUM\": \"PHONE_NUM\",\n","        \"DATE_TIME\": \"DATE_TIME\",\n","        \"DOMAIN\": \"DOMAIN\",\n","        \"IBAN_CODE\": \"IBAN_CODE\",\n","        \"IP_ADDRESS\": \"IP_ADDRESS\",\n","        \"INSTITUTION\": \"INSTITUTION\",\n","        \"LOGIN_NICK\": \"LOGIN_NICK\",\n","        \"MEDIA_NAME\": \"MEDIA_NAME\",\n","        \"NUMBER_EXPR\": \"NUMBER_EXPR\",\n","        \"OTHER\": \"OTHER\",\n","        \"CS_RC\": \"CS_RC\",\n","        \"CRYPTO\": \"CRYPTO\"\n","    }\n","\n","model = PresidioAnalyzerWrapper(analyzer_engine=analyzer, language=[\"cs\"])\n","\n","evaluator = Evaluator(model=model)\n","dataset = Evaluator.align_entity_types(\n","    deepcopy(input_samples), entities_mapping=presidio_entities_map\n",")\n","\n","evaluation_results = evaluator.evaluate_all(dataset)\n","results = evaluator.calculate_score(evaluation_results)\n","\n","entities, confmatrix = results.to_confusion_matrix()\n","\n","print(results)"]},{"cell_type":"markdown","metadata":{"id":"RbHsTCfIdHAk"},"source":["# Streamlit application\n","\n","For the implementation of the PII anonymizer tool itself was choosed a SDK Presidio together with a Streamlit framework.\n","\n","Presidio offers the tools to implement application for PII anonymization. Streamlit frameworks allows to create simple python-based graphic web applications.\n","\n","PII anonymizer source codes can be found here: https://github.com/ondrasekd/DP/tree/master/src/streamlit_app\n","\n","This notebook is meant as a way to simply run this application within the Google Colab environment."]},{"cell_type":"markdown","metadata":{"id":"G1xGOOf39v4h"},"source":["First, install Streamlit in this virtual machine session."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":17784,"status":"ok","timestamp":1654882256660,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"qVhg2EKvdJb7","outputId":"d7689361-b3e4-473f-de9a-27b1c8600878"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting streamlit==1.7.0\n","  Downloading streamlit-1.7.0-py2.py3-none-any.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 14.7 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: presidio-analyzer in /usr/local/lib/python3.7/dist-packages (2.2.28)\n","Requirement already satisfied: presidio-anonymizer in /usr/local/lib/python3.7/dist-packages (2.2.28)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (2.23.0)\n","Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (0.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (1.21.6)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (7.1.2)\n","Collecting validators\n","  Downloading validators-0.20.0.tar.gz (30 kB)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (21.4.0)\n","Collecting pydeck>=0.1.dev5\n","  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n","\u001b[K     |████████████████████████████████| 4.3 MB 42.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (2.8.2)\n","Collecting gitpython!=3.1.19\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 73.9 MB/s \n","\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (4.2.0)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (5.1.1)\n","Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (3.17.3)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (6.0.1)\n","Collecting watchdog\n","  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 8.1 MB/s \n","\u001b[?25hCollecting blinker\n","  Downloading blinker-1.4.tar.gz (111 kB)\n","\u001b[K     |████████████████████████████████| 111 kB 73.8 MB/s \n","\u001b[?25hRequirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (4.2.4)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (7.1.2)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (4.11.4)\n","Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (2.13.0)\n","Collecting base58\n","  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (21.3)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (1.5.1)\n","Collecting pympler>=0.9\n","  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n","\u001b[K     |████████████████████████████████| 164 kB 64.6 MB/s \n","\u001b[?25hCollecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from streamlit==1.7.0) (4.1.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.7.0) (4.3.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.7.0) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.7.0) (2.11.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit==1.7.0) (0.11.2)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit==1.7.0) (3.8.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.7.0) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit==1.7.0) (5.7.1)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit==1.7.0) (1.15.0)\n","Collecting ipykernel>=5.1.2\n","  Downloading ipykernel-6.13.1-py3-none-any.whl (133 kB)\n","\u001b[K     |████████████████████████████████| 133 kB 73.1 MB/s \n","\u001b[?25hRequirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==1.7.0) (5.1.1)\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit==1.7.0) (7.7.0)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (1.5.5)\n","Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (1.0.0)\n","Collecting jupyter-client>=6.1.12\n","  Downloading jupyter_client-7.3.4-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 75.1 MB/s \n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (5.4.8)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (0.1.3)\n","Collecting tornado>=5.0\n","  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n","\u001b[K     |████████████████████████████████| 428 kB 68.6 MB/s \n","\u001b[?25hCollecting ipython>=7.23.1\n","  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n","\u001b[K     |████████████████████████████████| 793 kB 71.8 MB/s \n","\u001b[?25hRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (4.8.0)\n","Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n","  Downloading prompt_toolkit-3.0.29-py3-none-any.whl (381 kB)\n","\u001b[K     |████████████████████████████████| 381 kB 69.5 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (57.4.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (2.6.1)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (0.18.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (0.2.0)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (3.6.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (1.1.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (5.4.0)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (0.2.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (0.8.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit==1.7.0) (2.0.1)\n","Requirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (23.0.0)\n","Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.12->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (4.10.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (2.15.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit==1.7.0) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (0.13.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (1.8.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (5.6.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from presidio-analyzer) (6.0)\n","Requirement already satisfied: phonenumbers>=8.12 in /usr/local/lib/python3.7/dist-packages (from presidio-analyzer) (8.12.49)\n","Requirement already satisfied: spacy>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from presidio-analyzer) (3.3.1)\n","Requirement already satisfied: tldextract in /usr/local/lib/python3.7/dist-packages (from presidio-analyzer) (3.3.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from presidio-analyzer) (2019.12.20)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (0.9.1)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (0.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (3.0.9)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (2.4.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (2.0.6)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (1.8.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (3.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (1.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (3.3.0)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (8.0.17)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (1.0.2)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (0.4.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (4.64.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (0.4.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.0->presidio-analyzer) (2.0.7)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit==1.7.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.0->presidio-analyzer) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==1.7.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==1.7.0) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==1.7.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit==1.7.0) (3.0.4)\n","Requirement already satisfied: pycryptodome>=3.10.1 in /usr/local/lib/python3.7/dist-packages (from presidio-anonymizer) (3.14.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (0.6.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (5.0.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (1.5.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (0.8.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit==1.7.0) (0.5.1)\n","Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.7/dist-packages (from tldextract->presidio-analyzer) (1.5.1)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract->presidio-analyzer) (3.7.0)\n","Building wheels for collected packages: blinker, validators\n","  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13478 sha256=8612231862b2a94cd4ea51fca76eec6a912869f16cd5fae3e41dc5747015b74b\n","  Stored in directory: /root/.cache/pip/wheels/22/f5/18/df711b66eb25b21325c132757d4314db9ac5e8dabeaf196eab\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=706676f7f531995114c4cf3912a2774d38f88658ecb692479e917dd2b5bcb02c\n","  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n","Successfully built blinker validators\n","Installing collected packages: tornado, prompt-toolkit, jupyter-client, ipython, ipykernel, smmap, gitdb, watchdog, validators, toml, pympler, pydeck, gitpython, blinker, base58, streamlit\n","  Attempting uninstall: tornado\n","    Found existing installation: tornado 5.1.1\n","    Uninstalling tornado-5.1.1:\n","      Successfully uninstalled tornado-5.1.1\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 1.0.18\n","    Uninstalling prompt-toolkit-1.0.18:\n","      Successfully uninstalled prompt-toolkit-1.0.18\n","  Attempting uninstall: jupyter-client\n","    Found existing installation: jupyter-client 5.3.5\n","    Uninstalling jupyter-client-5.3.5:\n","      Successfully uninstalled jupyter-client-5.3.5\n","  Attempting uninstall: ipython\n","    Found existing installation: ipython 5.5.0\n","    Uninstalling ipython-5.5.0:\n","      Successfully uninstalled ipython-5.5.0\n","  Attempting uninstall: ipykernel\n","    Found existing installation: ipykernel 4.10.1\n","    Uninstalling ipykernel-4.10.1:\n","      Successfully uninstalled ipykernel-4.10.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.13.1 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n","Successfully installed base58-2.1.1 blinker-1.4 gitdb-4.0.9 gitpython-3.1.27 ipykernel-6.13.1 ipython-7.34.0 jupyter-client-7.3.4 prompt-toolkit-3.0.29 pydeck-0.7.1 pympler-1.0.1 smmap-5.0.0 streamlit-1.7.0 toml-0.10.2 tornado-6.1 validators-0.20.0 watchdog-2.1.9\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["IPython","prompt_toolkit","tornado"]}}},"metadata":{},"output_type":"display_data"}],"source":["# user streamlit version 1.7.0 because of the installed google colab python version\n","!pip install streamlit==1.7.0 pandas presidio-analyzer presidio-anonymizer"]},{"cell_type":"markdown","metadata":{"id":"SSy9ZlVH-MMX"},"source":["You can run the PII Anonymizer tool either for CPU session of Google Colab or GPU session. GPU application gives better results.\n","\n","in order to use spacy models in a Streamlit based app, python package must be generated for each trained pipeline and then installed.\n","\n","Then, to expose the web application running on a Google Colab's virtual machine local host, it is run through a localtunnel tool. Running web application than can be accessed on a provided URL."]},{"cell_type":"markdown","metadata":{"id":"vjqt5vqW-gw_"},"source":["**CPU version**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8975,"status":"ok","timestamp":1654876745881,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"dRpgfBYjEYhH","outputId":"682a8e5a-4323-48c7-fbb1-c6ecdce385b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Building package artifacts: sdist\u001b[0m\n","\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/model-best/meta.json\n","\n","\u001b[38;5;1m✘ Package directory already exists\u001b[0m\n","Please delete the directory and try again, or use the `--force` flag to\n","overwrite existing directories.\n","\n"]}],"source":["nlp = spacy.load('/content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/model-best')\n","!python -m spacy package /content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/model-best /content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph --name CPU_fine_nomorph"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24056,"status":"ok","timestamp":1654876769926,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"pfdmUNnLEj8D","outputId":"8ce87717-3c31-4787-8dd2-358961ce7573"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/cs_CPU_fine_nomorph-0.0.0\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: spacy<3.4.0,>=3.3.1 in /usr/local/lib/python3.7/dist-packages (from cs-CPU-fine-nomorph==0.0.0) (3.3.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (57.4.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (3.0.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (8.0.17)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (0.9.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2.11.3)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (1.0.7)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2.23.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2.0.7)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (0.6.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (1.8.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2.4.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (1.0.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (4.64.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (1.21.6)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (0.4.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (3.3.0)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (4.1.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (3.0.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2.0.6)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (0.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (3.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.1->cs-CPU-fine-nomorph==0.0.0) (2.0.1)\n","Building wheels for collected packages: cs-CPU-fine-nomorph\n","  Building wheel for cs-CPU-fine-nomorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cs-CPU-fine-nomorph: filename=cs_CPU_fine_nomorph-0.0.0-py3-none-any.whl size=6615614 sha256=09a6208474d5356d89e475bb7760215234bf221f0ed3ad3b74676f0b350dc35d\n","  Stored in directory: /root/.cache/pip/wheels/9c/0b/90/789fe086c9ee3fbac87b5a3d4c83fbfbac37968b9405e551b7\n","Successfully built cs-CPU-fine-nomorph\n","Installing collected packages: cs-CPU-fine-nomorph\n","Successfully installed cs-CPU-fine-nomorph-0.0.0\n"]}],"source":["!pip install /content/drive/MyDrive/PIIAnonymizer/models/CPU_fine_nomorph/cs_CPU_fine_nomorph-0.0.0"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47168,"status":"ok","timestamp":1654879809543,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"Q6gxacEfs-hn","outputId":"e562e147-7de1-4b50-9f29-8e648181c498"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-06-10 16:49:23.080 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n","\u001b[K\u001b[?25hnpx: installed 22 in 2.944s\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://104.199.214.178:8501\u001b[0m\n","\u001b[0m\n","your url is: https://thin-candles-stay-104-199-214-178.loca.lt\n","/usr/local/lib/python3.7/dist-packages/spacy/util.py:833: UserWarning: [W095] Model 'cs_pipeline' (0.0.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n","  warnings.warn(warn_msg)\n","2022-06-10 16:49:41.598 Loaded recognizer: SpacyRecognizerCustom\n","2022-06-10 16:49:41.598 Loaded recognizer: CSRCRecognizer\n","2022-06-10 16:49:41.599 Loaded recognizer: CreditCardRecognizer\n","2022-06-10 16:49:41.599 Loaded recognizer: CryptoRecognizer\n","2022-06-10 16:49:41.599 Loaded recognizer: EmailRecognizer\n","2022-06-10 16:49:41.599 Loaded recognizer: IbanRecognizer\n","2022-06-10 16:49:41.599 Loaded recognizer: IpRecognizer\n","/usr/local/lib/python3.7/dist-packages/spacy/util.py:833: UserWarning: [W095] Model 'cs_CPU_fine_nomorph' (0.0.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.2.4). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n","  warnings.warn(warn_msg)\n","2022-06-10 16:49:41.827 Created NLP engine: spacy. Loaded models: ['cs']\n","2022-06-10 16:49:41.827 Fetching all recognizers for language cs\n","2022-06-10 16:49:41.827 Fetching all recognizers for language cs\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}],"source":["!streamlit run /content/DP/src/streamlit_app/presidio_streamlit_CPU_best.py & npx localtunnel --port 8501"]},{"cell_type":"markdown","metadata":{"id":"TiGiFagFBhkx"},"source":["**GPU version**"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34677,"status":"ok","timestamp":1654882083868,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"eANJyJMoP6Qx","outputId":"129f53b7-dd42-4db0-d485-65f11acfef7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[38;5;4mℹ Building package artifacts: sdist\u001b[0m\n","\u001b[38;5;2m✔ Including 1 package requirement(s) from meta and config\u001b[0m\n","spacy-transformers>=1.1.6,<1.2.0\n","\u001b[38;5;2m✔ Loaded meta.json from file\u001b[0m\n","/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/model-best/meta.json\n","\n","\u001b[38;5;1m✘ Package directory already exists\u001b[0m\n","Please delete the directory and try again, or use the `--force` flag to\n","overwrite existing directories.\n","\n"]}],"source":["nlp = spacy.load('/content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/model-best')\n","!python -m spacy package /content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/model-best /content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased --name GPU_bert_cased"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79668,"status":"ok","timestamp":1654882163521,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"gsLmXYrFP8Gy","outputId":"40837aae-abe8-45ac-d60b-294f121fdd0f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing ./drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/cs_GPU_bert_cased-0.0.0\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Requirement already satisfied: spacy<3.4.0,>=3.3.1 in /usr/local/lib/python3.7/dist-packages (from cs-GPU-bert-cased==0.0.0) (3.3.1)\n","Requirement already satisfied: spacy-transformers<1.2.0,>=1.1.6 in /usr/local/lib/python3.7/dist-packages (from cs-GPU-bert-cased==0.0.0) (1.1.6)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (1.0.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2.0.7)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (1.21.6)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (0.4.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (4.64.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2.23.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2.0.6)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (8.0.17)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (1.8.2)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (0.9.1)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (4.1.1)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (0.4.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (3.0.9)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2.11.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2.4.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (0.6.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (3.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (57.4.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (1.0.7)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (3.3.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (21.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (5.2.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2022.5.18.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (1.24.3)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (1.10.1+cu111)\n","Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (0.8.5)\n","Requirement already satisfied: transformers<4.20.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (4.19.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (0.7.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (0.12.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (4.11.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (3.7.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.20.0,>=3.4.0->spacy-transformers<1.2.0,>=1.1.6->cs-GPU-bert-cased==0.0.0) (2019.12.20)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.1->cs-GPU-bert-cased==0.0.0) (2.0.1)\n","Building wheels for collected packages: cs-GPU-bert-cased\n","  Building wheel for cs-GPU-bert-cased (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cs-GPU-bert-cased: filename=cs_GPU_bert_cased-0.0.0-py3-none-any.whl size=666693901 sha256=77faef2d6fe4ac6f3d3cece26d041c43b697249150540348760a267f9dfb99f1\n","  Stored in directory: /root/.cache/pip/wheels/3d/a0/60/92480eda7ca2fb534bb29f15b7a930e49d1d201183709e2746\n","Successfully built cs-GPU-bert-cased\n","Installing collected packages: cs-GPU-bert-cased\n","Successfully installed cs-GPU-bert-cased-0.0.0\n"]}],"source":["!pip install /content/drive/MyDrive/PIIAnonymizer/models/GPU_bert_cased/cs_GPU_bert_cased-0.0.0"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241458,"status":"ok","timestamp":1654882576697,"user":{"displayName":"David Ondrášek","userId":"01881239200037827325"},"user_tz":-120},"id":"1ZmN0S2aP9wl","outputId":"dca5e362-074e-4dc3-e0b9-1c362cce1aaa"},"outputs":[{"name":"stdout","output_type":"stream","text":["2022-06-10 17:32:15.855 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n","\u001b[K\u001b[?25hnpx: installed 22 in 2.077s\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.91.51.235:8501\u001b[0m\n","\u001b[0m\n","your url is: https://tangy-radios-stay-34-91-51-235.loca.lt\n","2022-06-10 17:32:42.413 Loaded recognizer: SpacyRecognizerCustom\n","2022-06-10 17:32:42.413 Loaded recognizer: CSRCRecognizer\n","2022-06-10 17:32:42.413 Loaded recognizer: CreditCardRecognizer\n","2022-06-10 17:32:42.413 Loaded recognizer: CryptoRecognizer\n","2022-06-10 17:32:42.413 Loaded recognizer: EmailRecognizer\n","2022-06-10 17:32:42.413 Loaded recognizer: IbanRecognizer\n","2022-06-10 17:32:42.413 Loaded recognizer: IpRecognizer\n","2022-06-10 17:32:46.976 Created NLP engine: spacy. Loaded models: ['cs']\n","2022-06-10 17:32:46.976 Fetching all recognizers for language cs\n","2022-06-10 17:32:46.976 Fetching all recognizers for language cs\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}],"source":["!streamlit run /content/DP/src/streamlit_app/presidio_streamlit_GPU_best.py & npx localtunnel --port 8501"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP34JHEcBRpinDK+BktQ/kG","collapsed_sections":["7MLyQC4alH-u","GVtjp_YxMWct","rPceov9IfPu4","pq-UMz3kfpe6"],"name":"PIIAnonymizer.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
